@inproceedings{10.1145/3500868.3561400,
	author = {Park, Soya},
	title = {Systems for Socially-Challenging Information Management},
	year = {2022},
	isbn = {9781450391900},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3500868.3561400},
	doi = {10.1145/3500868.3561400},
	abstract = {In collaborative settings, information management becomes even more challenging. In addition to the classic challenge of information management (i.e. information overload), collaboration also introduces social barriers between group members; this entails asymmetric roles, where different stakeholders have different levels of motivation, knowledge, social capital, authority, or time. To successfully manage their information, groups of people need to coordinate their needs and resources. In my thesis, I focus on building interfaces for lowering social burdens to negotiate and communicate the distribution of resources. I develop coordination systems that guide interaction for collaborative information-management tasks. I first introduce a system called Ziva, which supports interdisciplinary teams by coordinating information exchange. Then, I describe TaskLight, which aims to support information management during the help-seeking process. Lastly, I present challenges of coordinating tool preferences and a resulting system called CollaboRanger.},
	booktitle = {Companion Publication of the 2022 Conference on Computer Supported Cooperative Work and Social Computing},
	pages = {214–218},
	numpages = {5},
	keywords = {collaborative information management, online coordination, social friction, team coordination},
	location = {Virtual Event, Taiwan},
	series = {CSCW'22 Companion}
}


@inproceedings{10.1145/2141512.2141613,
	author = {Wallace, James R.},
	title = {Using teamwork and taskwork to study mixed-focus collaboration},
	year = {2012},
	isbn = {9781450310512},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2141512.2141613},
	doi = {10.1145/2141512.2141613},
	abstract = {The primary contribution of my work is a methodology for the study of teamwork and taskwork during mixed-focus collaboration. I am currently completing the third experimental study in a series of three that investigate the role of shared and personal displays in supporting collaboration. The first study compared single- and multi-display configurations, and found that single display systems supported coordination, whereas multi-display systems improved collaborative outcomes. The second study compared different shared display types and identified how they support group synchronization, monitoring, and grounding behaviours. The final study investigates information sharing when groups are supported by interactive tabletops and tablets.},
	booktitle = {Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work Companion},
	pages = {331–334},
	numpages = {4},
	keywords = {evaluation, methodology, multi-display environments, single display groupware, taskwork, teamwork},
	location = {<conf-loc>, <city>Seattle</city>, <state>Washington</state>, <country>USA</country>, </conf-loc>},
	series = {CSCW '12}
}


@inproceedings{10.1145/2556420.2556793,
	author = {Etzold, Jonas and Grimm, Paul and Schweitzer, J\"{o}rg and D\"{o}rner, Ralf},
	title = {kARbon: a collaborative MR web application for communicationsupport in construction scenarios},
	year = {2014},
	isbn = {9781450325417},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2556420.2556793},
	doi = {10.1145/2556420.2556793},
	abstract = {kARbon demonstrates a web-based mixed reality (MR) support and collaboration tool for a wide range of construction planning and supervising scenarios. We describe how the construction process can be supported for locally distributed workers, experts and decision makers by leveraging MR methods in combination with effective and pure web-based collaboration, interaction and presentation concepts. kARbon therefore combines classical CAD planning data with photo collections representing temporal snapshots of the associated construction site in a precise MR scene. We focus on our collaborative use case and describe how involved people in different locations and on different device types can collaborate and interact through our tool based on the power of modern web standards.},
	booktitle = {Proceedings of the Companion Publication of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
	pages = {9–12},
	numpages = {4},
	keywords = {3d web applications, collaboration, construction planning, cooperative work, mixed reality, supporting tools},
	location = {Baltimore, Maryland, USA},
	series = {CSCW Companion '14}
}


@inproceedings{10.1145/3626485.3626545,
	author = {Echtler, Florian and Maierh\"{o}fer, Vitus and Hansen, Nicolai Brodersen and Wimmer, Raphael},
	title = {Demonstrating SurfaceCast: Ubiquitous, Cross-Device Surface Sharing},
	year = {2023},
	isbn = {9798400704253},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3626485.3626545},
	doi = {10.1145/3626485.3626545},
	abstract = {Real-time online interaction is the norm today. Tabletops and other dedicated interactive surface devices with direct input and tangible interaction can enhance remote collaboration, and open up new interaction scenarios based on mixed physical/virtual components. However, they are only available to a small subset of users, as they usually require identical bespoke hardware for every participant, are complex to setup, and need custom scenario-specific applications. We present SurfaceCast, a software toolkit designed to merge multiple distributed, heterogeneous end-user devices into a single, shared mixed-reality surface. Supported devices include regular desktop and laptop computers, tablets, and mixed-reality headsets, as well as projector-camera setups and dedicated interactive tabletop systems. This device-agnostic approach provides a fundamental building block for exploration of a far wider range of usage scenarios than previously feasible, including future clients using our provided API. In this paper, we present various example application scenarios which we enhance through the multi-user and multi-device features of the framework. Our results show that the hardware- and content-agnostic architecture of SurfaceCast can run on a wide variety of devices with sufficient performance and fidelity for real-time interaction.},
	booktitle = {Companion Proceedings of the 2023 Conference on Interactive Surfaces and Spaces},
	pages = {65–68},
	numpages = {4},
	keywords = {WebRTC, collaboration, framework, interactive surface, software, streaming, tabletops, tangible, toolkit, video},
	location = {<conf-loc>, <city>Pittsburgh</city>, <state>PA</state>, <country>USA</country>, </conf-loc>},
	series = {ISS Companion '23}
}


@inproceedings{10.1145/192844.192888,
	author = {Furuta, Richard and Stotts, P. David},
	title = {Interpreted collaboration protocols and their use in groupware prototyping},
	year = {1994},
	isbn = {0897916891},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/192844.192888},
	doi = {10.1145/192844.192888},
	abstract = {The correct and timely creation of systems for coordination of group work depends on the ability to express, analyze, and experiment with protocols for managing multiple work threads. We present an evolution of the Trellis model that provides a formal basis for prototyping the coordination structure of a collaboration system. In Trellis, group interaction protocols are represented separately from the interface processes that use them for coordination. Protocols are interpreted (rather than compiled into applications) so group interactions can be changed as a collaborative task progresses. Changes can be made either by a person editing the protocol specification “on the fly” or by a silent “observation” process that participates in an application solely to  perform behavioral adaptations.Trellis uniquely mixes hypermedia browsing with collaboration support. We term this combination a hyperprogram, and we say that a hyperprogram integrates the description of a collaborative task with the information required for that task. As illustration, we describe a protocol for a moderated meeting and show a Trellis prototype conference tool controlled by this protocol.},
	booktitle = {Proceedings of the 1994 ACM Conference on Computer Supported Cooperative Work},
	pages = {121–131},
	numpages = {11},
	keywords = {Trellis, colored Petri net, coordination structure, dynamic protocol, formal methods, moderated meeting, process-based hypertext/hypermedia},
	location = {Chapel Hill, North Carolina, USA},
	series = {CSCW '94}
}


@inproceedings{10.1145/2998181.2998356,
	author = {Yim, Soobin and Wang, Dakuo and Olson, Judith and Vu, Viet and Warschauer, Mark},
	title = {Synchronous Collaborative Writing in the Classroom: Undergraduates' Collaboration Practices and their Impact on Writing Style, Quality, and Quantity},
	year = {2017},
	isbn = {9781450343350},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2998181.2998356},
	doi = {10.1145/2998181.2998356},
	abstract = {Group activities that use Google Docs for simultaneous collaborative writing and editing are increasingly common in higher education. Although studies show that synchronous collaboration can bring multiple benefits, such as enhanced productivity and writing quality, little is known about these writing practices in classrooms and their impact on students' writing. Using a mixed method approach, we conducted an empirical study that explores the different styles of synchronous collaboration in 45 Google Docs documents produced by 82 undergraduate students, and how students' practices affect the specific dimensions of the final text including quality. The results suggest that (a) out of four styles, Divide and Conquer style tended to produce better quality text whereas Main Writer had the lowest quality scores, and that (b) balanced participation and amount of peer editing led to longer texts with higher quality scores for content, evidence, but not organization or mechanics. Given these results, we suggest several design features for collaborative writing systems and propose guidelines for instructional practices.},
	booktitle = {Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
	pages = {468–479},
	numpages = {12},
	keywords = {cloud-based technology, collaborative writing, collocated, computational text analysis, computer-supported cooperative work, google docs, higher education, information visualization, synchronous collaboration},
	location = {Portland, Oregon, USA},
	series = {CSCW '17}
}


@inproceedings{10.1145/2145204.2145398,
	author = {Bartel, Jacob W. and Dewan, Prasun},
	title = {Towards multi-domain collaborative toolkits},
	year = {2012},
	isbn = {9781450310864},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2145204.2145398},
	doi = {10.1145/2145204.2145398},
	abstract = {A multi-domain collaboration toolkit hides heterogeneity of user-interface toolkits and associated domains from both programmers and end users of collaborative, widget-synchronizing, applications. We have developed such a system for the stand-alone, Eclipse, and web domains; and the AWT, Swing, SWT, and GWT single-user toolkits associated with these domains. Several new concepts are supported to meet these requirements including a widget server allowing a distributed widget client to manipulate widgets on an interactive device, flexible widget synchronization, flexible placement of widget listeners, "piping" centralized non-interactive replicas communicating with interactive user replicas, factory-based retargeting of the user-interface toolkit, and a new process architecture.},
	booktitle = {Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work},
	pages = {1297–1306},
	numpages = {10},
	keywords = {distributed user-interfaces, heterogeneity, multi-device interfaces, user-interface toolkits, web},
	location = {<conf-loc>, <city>Seattle</city>, <state>Washington</state>, <country>USA</country>, </conf-loc>},
	series = {CSCW '12}
}


@inproceedings{10.1145/2141512.2141549,
	author = {Gridling, Nicole and Meschtscherjakov, Alexander and Tscheligi, Manfred},
	title = {I need help! exploring collaboration in the car},
	year = {2012},
	isbn = {9781450310512},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2141512.2141549},
	doi = {10.1145/2141512.2141549},
	abstract = {Today a huge number of different driving assistance and navigation systems are available on the market. Often these systems fail to take into account the social nature and collaborative mechanism of driving. This paper presents a two-month ethnographic study of drivers and passengers, with the goal of understanding social and collaborative in-car activities while driving to inform in-car navigation design. We found that human assistance and collaborative behavior varied among different contextual situations. Above that User Experience (UX) factors such as trust and perceived safety have a main influence on the type of front-seat passenger assistance and level of collaboration. Based on these observations we present a design approach for collaborative navigation devices that can be used to inform future research and practical applications in automobile collaboration.},
	booktitle = {Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work Companion},
	pages = {87–90},
	numpages = {4},
	keywords = {interaction design, participatory and cooperative design, qualitative methods, user experience},
	location = {<conf-loc>, <city>Seattle</city>, <state>Washington</state>, <country>USA</country>, </conf-loc>},
	series = {CSCW '12}
}


@inproceedings{10.1145/2145204.2145305,
	author = {Yatani, Koji and Gergle, Darren and Truong, Khai},
	title = {Investigating effects of visual and tactile feedback on spatial coordination in collaborative handheld systems},
	year = {2012},
	isbn = {9781450310864},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2145204.2145305},
	doi = {10.1145/2145204.2145305},
	abstract = {Mobile and handheld devices have become platforms to support remote collaboration. But, their small form-factor may impact the effectiveness of the visual feedback channel often used to help users maintain an awareness of their partner's activities during synchronous collaborative tasks. We investigated how visual and tactile feedback affects collaboration on mobile devices, with emphasis on spatial coordination in a shared workspace. From two user studies, our results highlight different benefits of each feedback channel in collaborative handheld systems. Visual feedback can provide precise spatial information for collaborators, but degrades collaboration when the feedback is occluded, and sometimes can distract the user's attention. Spatial tactile feedback can reduce the overload of information in visual space and gently guides the user's attention to an area of interest. Our results also show that visual and tactile feedback can complement each other, and systems using both feedback channels can support better spatial coordination than systems using only one form of feedback.},
	booktitle = {Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work},
	pages = {661–670},
	numpages = {10},
	keywords = {collaboration, mobile/handheld devices, spatial coordination, tactile feedback, touch screen, visual feedback},
	location = {<conf-loc>, <city>Seattle</city>, <state>Washington</state>, <country>USA</country>, </conf-loc>},
	series = {CSCW '12}
}


@inproceedings{10.1145/2556420.2556480,
	author = {AlTarawneh, Ragaad and Bauer, Jens and Ebert, Achim},
	title = {A visual interactive environment for enhancing collaboration between engineers for the safety analysis mechanisms in embedded systems},
	year = {2014},
	isbn = {9781450325417},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2556420.2556480},
	doi = {10.1145/2556420.2556480},
	abstract = {Maintaining modern embedded systems requires close collaboration between engineers who designed them and engineers who analyzed possible failures in such systems in order to avoid any possible hazard. In this work, we present a collaborative visual platform that supports the safety analysis process of such systems in a collaborative manner. The platform consists of one large display and multiple smart devices (i.e., smartphones or tablets) through which users interact with the visual elements on the large display for understanding the failure mechanisms of the underlying system. This whole environment provides an intuitive visual interaction to speed up the communication between different users from different backgrounds.},
	booktitle = {Proceedings of the Companion Publication of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
	pages = {125–128},
	numpages = {4},
	keywords = {collaborative environment, embedded systems, immersive environment, safety aspects visualization},
	location = {Baltimore, Maryland, USA},
	series = {CSCW Companion '14}
}


@inproceedings{10.1145/2145204.2145388,
	author = {Nobarany, Syavash and Haraty, Mona and Fisher, Brian},
	title = {Facilitating the reuse process in distributed collaboration: a distributed cognition approach},
	year = {2012},
	isbn = {9781450310864},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2145204.2145388},
	doi = {10.1145/2145204.2145388},
	abstract = {Facilitating the reuse process and enabling unanticipated reuse can improve efficiency of distributed collaboration. However, supporting the reuse process in complex and dynamic contexts, where future use of information is difficult to predict, is challenging. Collaborative analytics exemplifies such a context. We employed distributed cognition theory to design a collaborative visual analytics system, called AnalyticStream, for facilitating reuse of analysis outcomes. In contrast with the commonly used detail-oriented approach to applying distributed cognition, we performed a high level analysis of the design situation and we identified the cognitive processes that could be distributed over people to facilitate their collaboration. We examined some of the ideas derived from the theoretical analysis, by designing a simple reminding process through recommending relevant pieces of analysis, as well as a mechanism for attention management through allowing users greater control over their shared activity streams. A mixed-methods study of AnalyticStream showed that suggesting relevant artefacts facilitated discovering and consequently reusing them, and provided context-relevant awareness of other analysts' activities.},
	booktitle = {Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work},
	pages = {1223–1232},
	numpages = {10},
	keywords = {collaborative visual analytics, distributed cognition, distributed collaboration, reusability, reuse},
	location = {<conf-loc>, <city>Seattle</city>, <state>Washington</state>, <country>USA</country>, </conf-loc>},
	series = {CSCW '12}
}


@inproceedings{10.1145/358916.358993,
	author = {Han, Richard and Perret, Veronique and Naghshineh, Mahmoud},
	title = {WebSplitter: a unified XML framework for multi-device collaborative Web browsing},
	year = {2000},
	isbn = {1581132220},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/358916.358993},
	doi = {10.1145/358916.358993},
	abstract = {WebSplitter symbolizes the union of pervasive multi-device computing and collaborative multi-user computing.  WebSplitter provides a unified XML framework that enables multi-device and multi-user Web browsing.  WebSplitter splits a requested Web page and delivers the appropriate partial view of each page to each user, or more accurately to each user's set of devices.  Multiple users can participate in the same browsing session, as in traditional conferencing groupware.  Depending on the access privileges of the user to the different components of content on each page, WebSplitter generates a personalized partial view.  WebSplitter further splits the partial view among the devices available to each user,  e.g. laptop, wireless PDA, projection display, stereo speakers, orchestrating a  composite presentation across the devices.  A wireless PDA can browse while remotely controlling the multimedia capabilities of nearby devices.  The architecture consists of an XML metadata policy file defining access privileges to XML tags on a Web page, a middleware proxy that splits XML Web content to create partial views, and a client-side component, e.g. applet, enabling user login and reception of pushed browsing data.  Service discovery finds and registers proxies, browsing sessions, and device capabilities.  We demonstrate the feasibility of splitting the different tags in an XML Web page to different end users browsers, and of pushing updates from the browsing session to heterogeneous devices, including a laptop and a PDA.},
	booktitle = {Proceedings of the 2000 ACM Conference on Computer Supported Cooperative Work},
	pages = {221–230},
	numpages = {10},
	keywords = {PDA, XML, co-browsing, collaboration, groupware, middleware, multi-device, partial view, pervasive, proxy, remote control, service discovery, wireless},
	location = {Philadelphia, Pennsylvania, USA},
	series = {CSCW '00}
}


@inproceedings{10.1145/2818048.2819967,
	author = {Ciolfi, Luigina and Avram, Gabriela and Maye, Laura and Dulake, Nick and Marshall, Mark T. and van Dijk, Dick and McDermott, Fiona},
	title = {Articulating Co-Design in Museums: Reflections on Two Participatory Processes},
	year = {2016},
	isbn = {9781450335928},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2818048.2819967},
	doi = {10.1145/2818048.2819967},
	abstract = {In this paper we reflect on the process of co-design by detailing and comparing two strategies for the participatory development of interaction concepts and prototypes in the context of technologically-enhanced museum visiting experiences. While much work in CSCW, HCI and related disciplines has examined different role configurations in co-design, more research is needed on examining how collaborative design processes can unfold in different ways. Here we present two instances of co-design of museum visiting aids, one stemming from an open brief, another from an initial working prototype; we discuss the process in each case and discuss how these alternative strategies presented the team with different possibilities as well as constraints, and led to different patterns of collaboration within the design team. Finally, we draw a set of themes for discussion and reflection to inform and aid researchers and practitioners participating in similar co-design processes, particularly in the domain of cultural heritage.},
	booktitle = {Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work &amp; Social Computing},
	pages = {13–25},
	numpages = {13},
	keywords = {participation, museums, design process, cultural heritage., collaboration, Co-design},
	location = {San Francisco, California, USA},
	series = {CSCW '16}
}


@inproceedings{10.1145/2141512.2141592,
	author = {Yu, Jianjun and Dong, Kejun and Nan, Kai},
	title = {Duckling: towards cloud service for scientific collaboration system},
	year = {2012},
	isbn = {9781450310512},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2141512.2141592},
	doi = {10.1145/2141512.2141592},
	abstract = {Duckling is an online cloud service system of scientific collaboration for the scientists in Chinese Academy of Sciences (CAS). We provide SaaS (Software as a Service) encapsulated the super-computing and PB scale of storage resources with different granularities, which provide easy web interface for the scientists to submit their research jobs, and datasets. We also rec-ommended several collaborative services during online interactive time. Duckling builds up a universal portal named ResearchOnline that helps amateur scientists to create their own online collaboration services with several operations and few fees. The quick increasement of diverse applications from different scientific field proves that our Duckling provides an emerging market for collaboration services under the environment of cloud computing.},
	booktitle = {Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work Companion},
	pages = {259–262},
	numpages = {4},
	keywords = {web services, scientific collaboration, duckling, cloud computing},
	location = {<conf-loc>, <city>Seattle</city>, <state>Washington</state>, <country>USA</country>, </conf-loc>},
	series = {CSCW '12}
}


@inproceedings{10.1145/587078.587113,
	author = {Li, Du and Li, Rui},
	title = {Transparent sharing and interoperation of heterogeneous single-user applications},
	year = {2002},
	isbn = {1581135602},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/587078.587113},
	doi = {10.1145/587078.587113},
	abstract = {Multi-user applications generally lag behind in features or compatibility with single-user applications. As a result, users are often not motivated to abandon their favorite single-user applications for groupware features that are less frequently used. A well-accepted approach, collaboration transparency, is able to convert off-the-shelf single-user applications into groupware without modifying the source code. However, existing systems have been largely striving to develop generic application-sharing mechanisms and undesirably force users to share the same application in cooperative work. In this paper we analyze this problem and present a novel approach (called intelligent collaboration transparency) to addressing this problem. Our approach allows for heterogeneous application sharing by considering the particular semantics of the applications and the collaboration task in question.},
	booktitle = {Proceedings of the 2002 ACM Conference on Computer Supported Cooperative Work},
	pages = {246–255},
	numpages = {10},
	keywords = {interoperation, heterogeneity, group editing, collaboration transparency, application sharing},
	location = {New Orleans, Louisiana, USA},
	series = {CSCW '02}
}


@inproceedings{10.1145/3022198.3026334,
	author = {Mikles, Sean P. and Suh, Hyewon and Kientz, Julie A.},
	title = {The Relevance of Theories and Models of Collaboration to Child Development Support Activities},
	year = {2017},
	isbn = {9781450346887},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3022198.3026334},
	doi = {10.1145/3022198.3026334},
	abstract = {Many stakeholders with different social and professional backgrounds can be involved in supporting a child's development. Experts note the importance of collaboration between all of these stakeholders in order to adequately support a child. Electronic systems have the potential to facilitate collaboration, and experts have suggested that models and theories relevant to collaboration can guide the design of collaborative systems. In this early exploratory work we investigate the relevance of various models and theories of collaboration and social interaction to the complex child development space.},
	booktitle = {Companion of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
	pages = {255–258},
	numpages = {4},
	keywords = {health, families, design, collaboration, children, child development},
	location = {Portland, Oregon, USA},
	series = {CSCW '17 Companion}
}


@inproceedings{10.1145/587078.587090,
	author = {Shen, Haifeng and Sun, Chengzheng},
	title = {Flexible notification for collaborative systems},
	year = {2002},
	isbn = {1581135602},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/587078.587090},
	doi = {10.1145/587078.587090},
	abstract = {Notification is an essential feature in collaborative systems, which determines a system's capability and flexibility in supporting different kinds of collaborative work. In the past years, various notification strategies have been designed for different systems. However, the design of notification components has been ad hoc, and the techniques used for supporting notification have been application-dependent. In this paper, we contribute a flexible notification framework that can be used to describe and compare a range of notification strategies used in existing collaborative systems, and to guide the design of notification components for new collaborative systems. The framework has been applied to the design of a notification component for a group editor, which uses a single notification mechanism to support various notification policies for meeting both real-time and non-real-time collaboration needs. In addition, a new operational transformation control algorithm has been devised in combination with the notification component, which is significantly simpler and more efficient than existing algorithms.},
	booktitle = {Proceedings of the 2002 ACM Conference on Computer Supported Cooperative Work},
	pages = {77–86},
	numpages = {10},
	keywords = {operational transformation, notification, group editor, concurrency control, collaborative system},
	location = {New Orleans, Louisiana, USA},
	series = {CSCW '02}
}


@inproceedings{10.1145/2531602.2531610,
	author = {Saupp\'{e}, Allison and Mutlu, Bilge},
	title = {How social cues shape task coordination and communication},
	year = {2014},
	isbn = {9781450325400},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2531602.2531610},
	doi = {10.1145/2531602.2531610},
	abstract = {To design computer-supported collaborative work (CSCW) systems that effectively support remote collaboration, designers need a better understanding of how people collaborate face-to-face and the mechanisms that they use to coordinate their actions. While research in CSCW has studied how specific social cues might facilitate collaboration in specific tasks, such as the role of gestures in video instruction, less is known about how a range of communicative cues might facilitate activities across many collaborative settings. In this paper, we model the predictive relationships between facial, gestural, and vocal cues and collaborative outcomes in three different tasks, drawing conclusions on how each cue might contribute to these outcomes in a given task and how such relationships generalize across tasks. The resulting models provide a quantitative understanding of the relative importance of each type of social cue in predicting collaborative outcomes, as well as a more thorough understanding of how the role of each social cue changes across tasks. Additionally, our results provide confirmation and illumination of prior findings in face-to-face and computer-mediated communication research.},
	booktitle = {Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
	pages = {97–108},
	numpages = {12},
	keywords = {social cues, face-to-face communication, design, computer-supported collaborative systems (cscw), computer-mediated communication (cmc)},
	location = {Baltimore, Maryland, USA},
	series = {CSCW '14}
}


@inproceedings{10.1145/2992154.2996879,
	author = {Davies, Cooper and White, Jade and McAllister, Alec and Saroka, Adam and Addam, Omar and Hendijani Fard, Fatemeh and Maurer, Frank},
	title = {A Toolkit for Building Collaborative Immersive Multi-Surface Applications},
	year = {2016},
	isbn = {9781450342483},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2992154.2996879},
	doi = {10.1145/2992154.2996879},
	abstract = {The paper describes a toolkit that integrates spatially-aware multi-surface systems with mixed-reality approaches to create immersive collaborative environments. The toolkit integrates multiple digital displays and multiple Microsoft HoloLens devices with multiple Kinects. The HoloLens' allow several users to look at the same virtual hologram while the Kinects enable them to use body movements to interact with these holograms as well as with other digital surfaces in a space. Effectively, the toolkit enables its users to build collaborative applications that utilize digital displays as well as the space between them to interact with information. Our approach also facilitates the management of virtual objects and overcomes gesture restrictions of HoloLens. We use the toolkit in a prototype application for improving the efficiency and response time in emergency management.},
	booktitle = {Proceedings of the 2016 ACM International Conference on Interactive Surfaces and Spaces},
	pages = {485–488},
	numpages = {4},
	keywords = {multiple devices, interaction, hand tracking, gestures, augmented reality},
	location = {Niagara Falls, Ontario, Canada},
	series = {ISS '16}
}


@inproceedings{10.1145/1460563.1460615,
	author = {Voida, Amy and Voida, Stephen and Greenberg, Saul and He, Helen Ai},
	title = {Asymmetry in media spaces},
	year = {2008},
	isbn = {9781605580074},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1460563.1460615},
	doi = {10.1145/1460563.1460615},
	abstract = {In any collaborative system, there are both symmetries and asymmetries present in the design of the technology and in the ways that technology is appropriated. Yet media space research tends to focus more on supporting and fostering the symmetries than the asymmetries. Throughout more than 20 years of media space research, the pursuit of increased symmetry, whether achieved through technical or social means, has been a recurrent theme. The research literature on the use of contemporary awareness systems, in contrast, displays little if any of this emphasis on symmetrical use; indeed, this body of research occasionally highlights the perceived value of asymmetry. In this paper, we unpack the different forms of asymmetry present in both media spaces and contemporary awareness systems. We argue that just as asymmetry has been demonstrated to have value in contemporary awareness systems, so might asymmetry have value in media spaces and in other CSCW systems, more generally. To illustrate, we present a media space that emphasizes and embodies multiple forms of asymmetry and does so in response to the needs of a particular work context.},
	booktitle = {Proceedings of the 2008 ACM Conference on Computer Supported Cooperative Work},
	pages = {313–322},
	numpages = {10},
	keywords = {reciprocity, media space, awareness, asymmetry},
	location = {San Diego, CA, USA},
	series = {CSCW '08}
}


@inproceedings{10.1145/2818048.2820003,
	author = {Anstead, Edward and Benford, Steve and Houghton, Robert},
	title = {MarathOn Multiscreen: Group Television Watching and Interaction in a Viewing Ecology},
	year = {2016},
	isbn = {9781450335928},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2818048.2820003},
	doi = {10.1145/2818048.2820003},
	abstract = {This paper reports and discusses the findings of an exploratory study into collaborative user practice with a multiscreen television application. MarathOn Multiscreen allows users to view, share and curate amateur and professional video footage of a community marathon event. Our investigations focused on collaborative sharing practices across different viewing activities and devices, the roles taken by different devices in a viewing ecology, and observations on how users consume professional and amateur content. Our Work uncovers significant differences in user behaviour and collaboration when engaged in more participatory viewing activities, such as sorting and ranking footage, which has implications for awareness of other users' interactions while viewing together and alone. In addition, user appreciation and use of amateur video content is dependent not only on quality and activity but their personal involvement in the contents.},
	booktitle = {Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work &amp; Social Computing},
	pages = {405–417},
	numpages = {13},
	keywords = {Video, Television, Multiscreen, Groupware},
	location = {San Francisco, California, USA},
	series = {CSCW '16}
}


@inproceedings{10.1145/2441776.2441857,
	author = {Agustina and Sun, Chengzheng},
	title = {Xpointer: an x-ray telepointer for relaxed-space-time wysiwis and unconstrained collaborative 3d design systems},
	year = {2013},
	isbn = {9781450313315},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2441776.2441857},
	doi = {10.1145/2441776.2441857},
	abstract = {Telepointers are a real-time collaborative feature to indicate pointing at shared objects. Existing telepointing techniques are, however, restricted to pointing at the foremost object underneath a mouse cursor in relaxed-space but strict-time WYSIWIS environments. In real-time collaborative 3D design systems with animation creation capabilities, multiple 3D objects can be simultaneously visible underneath mouse cursors for users to freely and concurrently work on and point at (unconstrained collaboration), and multiple users can view 3D workspaces and point from different viewing perspectives (relaxed-space WYSIWIS) and animation time frames (relaxed-time WYSIWIS). This paper contributes a novel XPointer technique with the capability of pointing through objects correctly and consistently from different viewing perspectives and time frames, even in the presence of concurrent editing work. This work is the first to identify and address these advanced 3D telepointing needs and capabilities, and to extend the concept of relaxed WYSIWIS to include the time aspect. The XPointer has been implemented in the CoMaya real-time collaborative 3D design system (demonstration video: http://cooffice.ntu.edu.sg/comaya/videoXPointer.php).},
	booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
	pages = {729–740},
	numpages = {12},
	keywords = {x-ray telepointers, workspace awareness, unconstrained collaboration, relaxed wysiwis, real-time collaborative 3d design systems, consistent telepointing},
	location = {San Antonio, Texas, USA},
	series = {CSCW '13}
}


@inproceedings{10.1145/2818048.2820002,
	author = {Bossen, Claus and Foss, Martin},
	title = {The Collaborative work of Hospital Porters: Accountability, Visibility and Configurations of Work},
	year = {2016},
	isbn = {9781450335928},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2818048.2820002},
	doi = {10.1145/2818048.2820002},
	abstract = {In this paper, we describe the collaborative work of hospital porters. The profession of hospital porters is understudied in sociology and in Computer Supported Cooperative Work, despite numerous studies of healthcare IT. We describe how a new IT system for hospital logistics provided porters with more influence on, and responsibility for their work; supported collaboration among porters, clinicians, and middle management; and effected a new ecology of visibility and accountability of porters' work. We discuss how the new system simultaneously supported collaboration and generated representations and accounts of porters' work. We compare the particular work arrangement in this study with other studies of porters' work, show the widely different configurations of how IT and work can be organized, and argue for the benefit of making comparative studies within CSCW. Finally, we argue for moving beyond dualisms of coordination and accountability for work.},
	booktitle = {Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work &amp; Social Computing},
	pages = {965–979},
	numpages = {15},
	keywords = {visibility., task management, hospital porters, hospital orderlies, hospital logistics, healthcare IT, cooperative work, CSCW, Accountability},
	location = {San Francisco, California, USA},
	series = {CSCW '16}
}


@inproceedings{10.1145/2441776.2441781,
	author = {Gao, Ge and Hinds, Pamela and Zhao, Chen},
	title = {Closure vs. structural holes: how social network information and culture affect choice of collaborators},
	year = {2013},
	isbn = {9781450313315},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2441776.2441781},
	doi = {10.1145/2441776.2441781},
	abstract = {Collaboration is important to successful organizations and how coworkers are selected is crucial to the dynamics of effective collaborations. In this study we explore how people use social network information, which is increasingly accessible on enterprise systems in organizations, to choose people with whom to collaborate. We conducted a scenario-based study of 459 respondents in a global high-tech company. Our data indicate cultural differences in how social network information was valued when choosing a collaborator. The Chinese, consistent with the cultural value of Guanxi, more closely followed a closure model, whereas Americans favored neither a closure nor a structural holes model. These results provide new insights into how needs for social network information may vary between cultures and how social networking sites might support workers in choosing collaborators from within and across national cultures.},
	booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
	pages = {5–18},
	numpages = {14},
	keywords = {willingness to collaborate, structural holes, social network sites (sns), national culture, guanxi, closure},
	location = {San Antonio, Texas, USA},
	series = {CSCW '13}
}


@inproceedings{10.1145/2818048.2819962,
	author = {Keegan, Brian C. and Lev, Shakked and Arazy, Ofer},
	title = {Analyzing Organizational Routines in Online Knowledge Collaborations: A Case for Sequence Analysis in CSCW},
	year = {2016},
	isbn = {9781450335928},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2818048.2819962},
	doi = {10.1145/2818048.2819962},
	abstract = {Research into socio-technical systems like Wikipedia has overlooked important structural patterns in the coordination of distributed work. This paper argues for a conceptual reorientation towards sequences as a fundamental unit of analysis for understanding work routines in online knowledge collaboration. We outline a research agenda for researchers in computer-supported cooperative work (CSCW) to understand the relationships, patterns, antecedents, and consequences of sequential behavior using methods already developed in fields like bio-informatics. Using a data set of 37,515 revisions from 16,616 unique editors to 96 Wikipedia articles as a case study, we analyze the prevalence and significance of different sequences of editing patterns. We illustrate the mixed method potential of sequence approaches by interpreting the frequent patterns as general classes of behavioral motifs. We conclude by discussing the methodological opportunities for using sequence analysis for expanding existing approaches to analyzing and theorizing about co-production routines in online knowledge collaboration.},
	booktitle = {Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work &amp; Social Computing},
	pages = {1065–1079},
	numpages = {15},
	keywords = {socio-technical system, sequence analysis, routines, peer production, organizational practice, online knowledge collaboration, Wikipedia},
	location = {San Francisco, California, USA},
	series = {CSCW '16}
}


@inproceedings{10.1145/1031607.1031610,
	author = {Yang, Yi and Li, Du},
	title = {Separating data and control: support for adaptable consistency protocols in collaborative systems},
	year = {2004},
	isbn = {1581138105},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1031607.1031610},
	doi = {10.1145/1031607.1031610},
	abstract = {Consistency control is critical for the correct functioning of distributed collaboration support systems. A large number of consistency control methods have appeared in the literature with different design tradeoffs and usability implications. However, there has been relatively little work on how to accommodate different protocols and variations in one framework to address the dynamic needs of collaboration. In this paper, we propose a novel approach for supporting adaptable consistency protocols in collaborative systems. Our approach cleanly separates data and control, allowing consistency protocols to be dynamically attached to shared data at the object level. Protocols can be switched at run time without modifying source code.},
	booktitle = {Proceedings of the 2004 ACM Conference on Computer Supported Cooperative Work},
	pages = {11–20},
	numpages = {10},
	keywords = {groupware framework, concurrency control, component-based development, collaborative systems, adaptability},
	location = {Chicago, Illinois, USA},
	series = {CSCW '04}
}


@inproceedings{10.1145/2685553.2702686,
	author = {Ellwanger, Dayton and Dillon, Nick and Wu, Tim and Carter, Jason and Dewan, Prasun},
	title = {Scalable Mixed-Focus Collaborative Difficulty Resolution: A Demonstration},
	year = {2015},
	isbn = {9781450329460},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2685553.2702686},
	doi = {10.1145/2685553.2702686},
	abstract = {In mixed-focus collaboration, users opportunistically switch between synchronous and asynchronous collaboration. We have developed a special case of this collaboration model in which the switch occurs when users face and overcome difficulty and the level of sharing in the synchronous mode can vary. The model supports multiple forms and degrees of awareness of the remote difficulty, and allows multiple kinds and degrees of sharing. It is scalable in that it allows a single helper to resolve the difficulties of a large number of people in difficulty. It has been implemented for a programming class and motivated by experience using a previous system in such a class. However, in principle, its structure is independent of the activity causing difficulty. A video demonstration of this work is available at http://youtu.be/1-AqMCidx48.},
	booktitle = {Proceedings of the 18th ACM Conference Companion on Computer Supported Cooperative Work &amp; Social Computing},
	pages = {53–56},
	numpages = {4},
	keywords = {recommender systems, cscw},
	location = {Vancouver, BC, Canada},
	series = {CSCW'15 Companion}
}


@inproceedings{10.1145/2675133.2675176,
	author = {Johnson, Steven and Gibson, Madeleine and Mutlu, Bilge},
	title = {Handheld or Handsfree? Remote Collaboration via Lightweight Head-Mounted Displays and Handheld Devices},
	year = {2015},
	isbn = {9781450329224},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2675133.2675176},
	doi = {10.1145/2675133.2675176},
	abstract = {Emerging wearable and mobile communication technologies, such as lightweight head-mounted displays (HMDs) and handheld devices, promise support for everyday remote collaboration. Despite their potential for widespread use, their effectiveness as collaborative tools is unknown, particularly in physical tasks involving mobility. To better understand their impact on collaborative behaviors, perceptions, and performance, we conducted a two-by-two (technology type: HMD vs. tablet computer; task setting: static vs. dynamic) between-subjects study where participants (n=66) remotely collaborated as ``helper' and ``worker' pairs in the construction of a physical object. Our results showed that, in the dynamic task, HMD use enabled helpers to offer more frequent directing commands and more proactive assistance, resulting in marginally faster task completion. In the static task, while tablet use helped convey subtle visual information, helpers and workers had conflicting perceptions of how the two technologies contributed to their success. Our findings offer strong design and research implications, underlining the importance of a consistent view of the shared workspace and the differential support collaborators with different roles receive from technologies.},
	booktitle = {Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
	pages = {1825–1836},
	numpages = {12},
	keywords = {wearable computing, videoconferencing, tablet computers, remote collaboration, head-mounted displays (hmds), handheld devices, computer-supported cooperative work},
	location = {Vancouver, BC, Canada},
	series = {CSCW '15}
}


@inproceedings{10.1145/2992154.2996359,
	author = {Anslow, Craig and Campos, Pedro and Lucero, Andr\'{e}s and Grisoni, Laurent and Augstein, Mirjam and Wallace, James},
	title = {Collaboration Meets Interactive Surfaces and Spaces (CMIS): Walls, Tables, Mobiles, and Wearables},
	year = {2016},
	isbn = {9781450342483},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2992154.2996359},
	doi = {10.1145/2992154.2996359},
	abstract = {The CMIS workshop proposes to bring together researchers who are interested in improving collaborative experiences through the combination of multiple interaction surfaces with diverse sizes and formats, ranging from large-scale walls, to tables, mobiles, and wearables. The opportunities for innovation exist, but the ISS, CHI, CSCW, and other HCI communities have not yet thoroughly addressed the problem of bringing effective collaboration activities together using multiple interactive surfaces, especially in complex work domains. Of particular interest is the potential synergy that one can obtain by effectively combining different-sized surfaces and sharing information between devices.},
	booktitle = {Proceedings of the 2016 ACM International Conference on Interactive Surfaces and Spaces},
	pages = {505–508},
	numpages = {4},
	keywords = {wearables, tabletops, multi-touch interaction, mobile, large display walls, interactive surfaces, collaboration},
	location = {Niagara Falls, Ontario, Canada},
	series = {ISS '16}
}


@inproceedings{10.1145/3343055.3360742,
	author = {Kim, Chelhwon and Chiu, Patrick and Tjahjadi, Yulius},
	title = {A Web-Based Remote Assistance System with Gravity-Aware 3D Hand Gesture Visualization},
	year = {2019},
	isbn = {9781450368919},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3343055.3360742},
	doi = {10.1145/3343055.3360742},
	abstract = {We present a remote assistance system that enables a remotely located expert to provide guidance using hand gestures to a customer who performs a physical task in a different location. The system is built on top of a web-based real-time media communication framework which allows the customer to use a commodity smartphone to send a live video feed to the expert, from which the expert can see the view of the customer's workspace and can show his/her hand gestures over the video in real-time. The expert's hand gesture is captured with a hand tracking device and visualized with a rigged 3D hand model on the live video feed. The system can be accessed via a web browser, and it does not require any app software to be installed on the customer's device. Our system supports various types of devices including smartphone, tablet, desktop PC, and smart glass. To improve the collaboration experience, the system provides a novel gravity-aware hand visualization technique.},
	booktitle = {Proceedings of the 2019 ACM International Conference on Interactive Surfaces and Spaces},
	pages = {319–322},
	numpages = {4},
	keywords = {web real-time communication, remote assistance, hand gestures, augmented reality},
	location = {<conf-loc>, <city>Daejeon</city>, <country>Republic of Korea</country>, </conf-loc>},
	series = {ISS '19}
}


@inproceedings{10.1145/1031607.1031609,
	author = {Chung, Goopeel and Dewan, Prasun},
	title = {Towards dynamic collaboration architectures},
	year = {2004},
	isbn = {1581138105},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1031607.1031609},
	doi = {10.1145/1031607.1031609},
	abstract = {In this paper, we introduce the concept of dynamically changing between centralized, replicated, and hybrid collaboration architectures. It is implemented by providing users a function that dynamically changes the mapping between user-interface and program components. We decompose the function into more primitive commands that are executed autonomously by individual users. These commands require a mechanism to dynamically replicate user-interface and program components on a user's site. We present a logging approach for implementing the mechanism that records input (output) messages sent to one incarnation of a program (user-interface) component, and replays the recorded messages to a different incarnation of the component. Preliminary experiments with an implementation of the mechanism show that response and completion times can improve by dynamically changing the architecture to adapt to changes to the set of users in a collaboration session involving a mix of mobile and stationary devices.},
	booktitle = {Proceedings of the 2004 ACM Conference on Computer Supported Cooperative Work},
	pages = {1–10},
	numpages = {10},
	keywords = {mobile collaboration, latecomers, collaboration architecture, application sharing, ad-hoc collaboration},
	location = {Chicago, Illinois, USA},
	series = {CSCW '04}
}


@inproceedings{10.1145/3022198.3026327,
	author = {Wahl, Andreas M. and Endler, Gregor and Schwab, Peter K. and Herbst, Sebastian and Lenz, Richard},
	title = {We Can Query More than We Can Tell: Facilitating Collaboration Through Query-Driven Knowledge-Sharing},
	year = {2017},
	isbn = {9781450346887},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3022198.3026327},
	doi = {10.1145/3022198.3026327},
	abstract = {We introduce Query-driven Knowledge-Sharing Systems (QKSS), which extend data management systems with knowledge-sharing capabilities to facilitate collaboration among different teams of data scientists. Relevant tacit knowledge about data sources is extracted from SQL query logs and externalized to support data source discovery and data integration. By studying this collaborative knowledge, data scientists are enabled to formulate effective analytical queries over unfamiliar data sources.},
	booktitle = {Companion of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
	pages = {335–338},
	numpages = {4},
	keywords = {knowledge sharing, data source discovery, data integration, collaborative data science},
	location = {Portland, Oregon, USA},
	series = {CSCW '17 Companion}
}


@inproceedings{10.1145/1031607.1031698,
	author = {Wang, H. and Blevis, E.},
	title = {Concepts that support collocated collaborative work inspired by the specific context of industrial designers},
	year = {2004},
	isbn = {1581138105},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1031607.1031698},
	doi = {10.1145/1031607.1031698},
	abstract = {Based on a naturalistic study of industrial designers engaged in collocated collaborative design work in a technologically unsophisticated environment, we observed a number of interactions that lead to a number of insights, namely, (1) seating and the shape and orientation of the working surface has an effect on line of sight and eye-contact behaviors, (2) being able to reach objects on the working surface effects an individual collaborator's ability to become the focus of attention, (3) in collaborative work, people may work on the same document or divide labors to work on different documents simultaneously, (4) supporting the use of conventional artifacts that users are familiar with is as important as supporting the use of informational devices, (5) large workspaces with different privacy levels support both the needs of sharing information and the needs of keeping information private, (6) changes of document orientation socially represents a corresponding change of control and privacy level. From these insights and from other sources in the literature, we describe and illustrate a number of concepts for integrated technologies and environments that can support collocated collaborative work specifically in the context of design work. These concepts are intended as an exercise in divergent design thinking that owes to carefully constructed insights based on observations.},
	booktitle = {Proceedings of the 2004 ACM Conference on Computer Supported Cooperative Work},
	pages = {546–549},
	numpages = {4},
	keywords = {naturalistic study, insight development, ethnography, concept sketching, collaborative design, HCI, CSCW},
	location = {Chicago, Illinois, USA},
	series = {CSCW '04}
}


@inproceedings{10.1145/1180875.1180952,
	author = {Danis, Catalina},
	title = {Forms of collaboration in high performance computing: exploring implications for learning},
	year = {2006},
	isbn = {1595932496},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1180875.1180952},
	doi = {10.1145/1180875.1180952},
	abstract = {Successful collaboration is not only an occasion for the accomplishment of shared goals, but also provides opportunities for individual collaborators to learn from each other. Extended interaction allows for participants to resolve personal and professional differences and thus create a foundation for successful collaboration. This paper contrasts opportunities for learning in short-term and long-term collaboration in the context of scientists working with High Performance Computing (HPC) system experts. It explores how factors conducive to successful collaboration in longer, more tightly organized collaboration might be adapted in more transient collaboration between scientists and HPC consultants.},
	booktitle = {Proceedings of the 2006 20th Anniversary Conference on Computer Supported Cooperative Work},
	pages = {501–504},
	numpages = {4},
	keywords = {teams, learning, consultants, collaboration},
	location = {Banff, Alberta, Canada},
	series = {CSCW '06}
}


@inproceedings{10.1145/2685553.2699009,
	author = {Johansen, Andreas Kaas and Vahr Bjarn\o{} Lauridsen, Frederik and Manea, Vlad and Slavin-Borovskij, Konstantin and M\o{}nsted, Troels},
	title = {Improving Coordination of Care Centers for the Elderly through IT Support},
	year = {2015},
	isbn = {9781450329460},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2685553.2699009},
	doi = {10.1145/2685553.2699009},
	abstract = {In Denmark, care of elderly people involves numerous and relatively autonomous care providers, including care centers, activity centers, physiotherapists, doctors, and other specialists. However, due to a poor coordination of activities, many elderly experience a lack of continuity of care, missed appointments, and general discomfort. In this poster we report on preliminary findings from a project aimed at creating improved IT support for coordination of care for the elderly in a Danish municipality. We propose that in order to successfully support heterogeneous collaboration, our system must address the disruptions in the existing routines, minimize the inherent articulation work, and coherently unify their coordination mechanisms.},
	booktitle = {Proceedings of the 18th ACM Conference Companion on Computer Supported Cooperative Work &amp; Social Computing},
	pages = {211–214},
	numpages = {4},
	keywords = {heterogeneous collaboration, elder care, coordination mechanisms},
	location = {Vancouver, BC, Canada},
	series = {CSCW'15 Companion}
}


@inproceedings{10.1145/3272973.3273013,
	author = {Alharthi, Sultan A. and Spiel, Katta and Hamilton, William A. and Bonsignore, Elizabeth and Toups Dugas, Phoebe O.},
	title = {Collaborative Mixed Reality Games},
	year = {2018},
	isbn = {9781450360180},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3272973.3273013},
	doi = {10.1145/3272973.3273013},
	abstract = {Collaborative mixed reality games enable shared social experiences, in which players interact with the physical and virtual game environment, and with other players in real-time. Recent advances in technology open a range of opportunities for designing new and innovative collaborative mixed reality games, but also raise questions around design, technical requirements, immersion, safety, and player experience. This workshop seeks to bring together researchers, designers, practitioners, and players to identify the most pressing challenges that need to be addressed in the next decade, discuss opportunities to overcome these challenges, and highlight lessons learned from past designs of such games. Participants will present their ideas, assemble and discuss a collection of related papers, outline a unifying research agenda, and engage in an outdoor game ideation and prototyping session. We anticipate that the CSCW community can contribute to designing the next generation of collaborative mixed reality games and technologies and to support the growth of research and development in this exciting and emerging area.},
	booktitle = {Companion of the 2018 ACM Conference on Computer Supported Cooperative Work and Social Computing},
	pages = {447–454},
	numpages = {8},
	keywords = {workshop, social games, mixed reality, location-based, games, cscw, collaboration, augmented reality},
	location = {<conf-loc>, <city>Jersey City</city>, <state>NJ</state>, <country>USA</country>, </conf-loc>},
	series = {CSCW '18 Companion}
}


@inproceedings{10.1145/2992154.2996787,
	author = {Corona, Nicola and Foddai, Roberto and Iacolina, Samuel Aldo and Mannai, Agnese},
	title = {Fun-f! Game-furniture Experimenting Interactive Surfaces for Children's Sensory Learning},
	year = {2016},
	isbn = {9781450342483},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2992154.2996787},
	doi = {10.1145/2992154.2996787},
	abstract = {This work describes Fun-f, a game-furniture for kids designed as a tool of sensory and relational discovery. We introduce the Montessori 2.0 concept, mixing technology and pedagogical theories on the relationships between objects, senses and child growth. Offering a complete sensory experience, our project consists in a sensory labyrinth composed by different modules related to all of the five primary senses. The Fun-f prototype follows a modular design allowing to create different labyrinths with the aim to propose personalized sensory paths and interactive experiences. Its design defines spaces supporting both personal and collaborative experiences, helping kids of different ages to increase their own cognitive, sensory and relational abilities by means of a learning-through-play environment.},
	booktitle = {Proceedings of the 2016 ACM International Conference on Interactive Surfaces and Spaces},
	pages = {391–396},
	numpages = {6},
	keywords = {sensory, responsive, learning-through-play, learning, interactive, game, furniture, education, design},
	location = {Niagara Falls, Ontario, Canada},
	series = {ISS '16}
}


@inproceedings{10.1145/2998181.2998271,
	author = {Alcaidinho, Joelle and Freil, Larry and Kelly, Taylor and Marland, Kayla and Wu, Chunhui and Wittenbrook, Bradley and Valentin, Giancarlo and Jackson, Melody},
	title = {Mobile Collaboration for Human and Canine Police Explosive Detection Teams},
	year = {2017},
	isbn = {9781450343350},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2998181.2998271},
	doi = {10.1145/2998181.2998271},
	abstract = {We designed a communication system for law enforcement officers to use when conducting explosive detection searches with multiple agencies. Dogs trained in explosive detection work alongside human handlers to form a K9 team, which are an integral part of these searches. Officers in K9 teams have a strong bond and communication with these dogs, but noisy locations, long distances, and crowded spaces present challenges. In addition, other officers assigned as backup often lack the experience to read the cues from the canine, which hinders the speed and effectiveness of the team. Coordinating a search with teams from different municipalities presents challenges due to a lack of standard collaboration tools. Getting the right information as quickly as possible saves lives, whether this information is about the areas that have been searched or the location of an explosive device. We hope that in addition to increasing public safety, our system will make working conditions safer for law enforcement officers and their canines.},
	booktitle = {Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
	pages = {925–933},
	numpages = {9},
	keywords = {police, law enforcement, k9, explosive detection, collaborative maps, animal computer-interaction},
	location = {Portland, Oregon, USA},
	series = {CSCW '17}
}


@inproceedings{10.1145/1460563.1460636,
	author = {Kim, Taemie and Chang, Agnes and Holland, Lindsey and Pentland, Alex Sandy},
	title = {Meeting mediator: enhancing group collaborationusing sociometric feedback},
	year = {2008},
	isbn = {9781605580074},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1460563.1460636},
	doi = {10.1145/1460563.1460636},
	abstract = {We present the Meeting Mediator (MM), a real-time portable system that detects social interactions and provides persuasive feedback to enhance group collaboration. Social interactions is captured using Sociometric badges [17] and are visualized on mobile phones to promote behavioral change. Particularly in distributed collaborations, MM attempts to bridge the gap among the distributed groups by detecting and communicating social signals. In a study on brainstorming and problem solving meetings, MM had a significant effect on overlapping speaking time and interactivity level without distracting the subjects. The Sociometric badges were also able to detect dominant players in the group and measure their influence on other participants. Most interestingly, in groups with one or more dominant people, MM effectively reduced the dynamical difference between co-located and distributed collaboration as well as the behavioral difference between dominant and non-dominant people. Our system encourages change in group dynamics that may lead to higher performance and satisfaction. We envision that MM will be deployed in real-world organizations to improve interactions across various group collaboration contexts.},
	booktitle = {Proceedings of the 2008 ACM Conference on Computer Supported Cooperative Work},
	pages = {457–466},
	numpages = {10},
	keywords = {sociometric sensors, social visualization, meeting support, dominance, cscw},
	location = {San Diego, CA, USA},
	series = {CSCW '08}
}


@inproceedings{10.1145/2818052.2874330,
	author = {Papagelis, Manos and Krijnen, Thomas F. and Elshenawy, Mohamed and Konomi, Theohar and Fang, Roy and El-Diraby, Tamer},
	title = {Green2.0: Enabling Complex Interactions Between Buildings and People},
	year = {2016},
	isbn = {9781450339506},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2818052.2874330},
	doi = {10.1145/2818052.2874330},
	abstract = {Professionals and researchers of the Architectural, Engi-neering &amp; Construction (AEC) industry are challenged by the increasing complexity of designing, constructing and op-erating a building. This typically requires close cooperation of actors having different backgrounds and interests. Tra-ditionally, this cooperation happens in an ad-hoc way and information exchange occurs through conventional general-purpose communication channels, such as paper or email. This communication and collaboration process can be inad-equate and inefficient, as it makes room for many different interpretations, mistakes and errors and can eventually lead to schedule and cost alterations. We present Green2.0, a system that tries to leverage advancements in building in-formation modeling to facilitate the collaboration process. The system integrates energy-efficiency simulation tools, and methods for online social network analysis to enable a data-driven approach to building design, construction and operation. By sharing all information online, all project ac-tors can access relevant information when they need so that everyone can work efficient together. The system aims to advance the current state of the art by bringing about a fundamental shift in the way that AEC professionals work together throughout a building's lifecycle.},
	booktitle = {Proceedings of the 19th ACM Conference on Computer Supported Cooperative Work and Social Computing Companion},
	pages = {77–80},
	numpages = {4},
	keywords = {Sustainability, Open Data, Collaboration, City Science, BIM},
	location = {San Francisco, California, USA},
	series = {CSCW '16 Companion}
}


@inproceedings{10.1145/1958824.1958904,
	author = {Howison, James and Herbsleb, James D.},
	title = {Scientific software production: incentives and collaboration},
	year = {2011},
	isbn = {9781450305563},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1958824.1958904},
	doi = {10.1145/1958824.1958904},
	abstract = {Software plays an increasingly critical role in science, including data analysis, simulations, and managing workflows. Unlike other technologies supporting science, software can be copied and distributed at essentially no cost, potentially opening the door to unprecedented levels of sharing and collaborative innovation. Yet we do not have a clear picture of how software development for science fits into the day-to-day practice of science, or how well the methods and incentives of its production facilitate realization of this potential. We report the results of a multiple-case study of software development in three fields: high energy physics, structural biology, and microbiology. In each case, we identify a typical publication, and use qualitative methods to explore the production of the software used in the science represented by the publication. We identify several different production systems, characterized primarily by differences in incentive structures. We identify ways in which incentives are matched and mismatched with the needs of the science fields, especially with respect to collaboration.},
	booktitle = {Proceedings of the ACM 2011 Conference on Computer Supported Cooperative Work},
	pages = {513–522},
	numpages = {10},
	keywords = {software ecosystem, software development, scientific software, scholarly publishing},
	location = {Hangzhou, China},
	series = {CSCW '11}
}
@article{10.1145/3648617,
	author = {Bj\o{}rn, Pernille and Busboom, Juliane and Duckert, Melanie and B\o{}dker, Susanne and Shklovski, Irina and Hoggan, Eve and Dunn, Kellie and Mu, Qianqian and Barkhuus, Louise and Boulus-R\o{}dje, Nina},
	title = {Achieving Symmetry in Synchronous Interaction in Hybrid Work is Impossible},
	year = {2024},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	issn = {1073-0516},
	url = {https://doi.org/10.1145/3648617},
	doi = {10.1145/3648617},
	abstract = {Designing new technologies to support synchronous interaction across distance has for many years focused on creating symmetry for participation between geographically distributed actors. Symmetry in synchronous interaction has, to some extent, been achieved technologically (while multiple social, historical, political, and hierarchical concerns continue to exist) and proven empirically in the increased use of remote-work technologies that were used during the pandemic. However, synchronous interaction in hybrid work is achieved differently, since the asymmetry produced by some participants being collocated while others geographically distributed introduces increased complexities for such interactions. Focusing on this challenge, we ask: To what extent can symmetry in cooperative work engagements be achieved in hybrid work contexts? We explore this question by interrogating multiple different empirical examples of synchronous hybrid interaction collected across different organizations, activities, and events. We found that the effort required to accomplish hybrid work includes additional articulation work necessary for bounding multiple intertwined artefacts across sites, devices, and applications. Further, the multiple artefacts setup across sites, combined with asymmetric collocation across participants, produce incongruence in technological frames of reference for each participant. All participants in hybrid work have only partial access to the hybrid setup, and no single person has access to the complete setup. The incongruence in technological frames produces insurmountable gaps in collaboration, causing all hybrid work situations to be characterized fundamentally by asymmetric relationships. We argue that symmetry in hybrid synchronous interaction is impossible to attain in attempts to solve this problem through design. Instead, we propose that designers of cooperative technologies for hybrid work shift towards developing artefact-ecologies supporting hybrid work, focusing on asymmetry as a necessary feature. Fundamentally, the design strategy should explore novel ways of taking advantage of the multiple different artefact-ecologies which serve as the foundation for the hybrid collaboration. Instead of striving for symmetry, we propose to feature asymmetric conditions in future technology designs for hybrid interaction.},
	note = {Just Accepted},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	month = {feb},
	keywords = {Distance, Global software development, Ethnography, Comparative studies, Incongruence, Synchronous interaction, Hybrid work, Workshop, Collaboration across distance, Covid}
}


@article{10.1145/1035575.1035579,
	author = {Velez, Maria and Tremaine, Marilyn Mantei and Sarcevic, Aleksandra and Dorohonceanu, Bogdan and Krebs, Allan and Marsic, Ivan},
	title = {"Who's in charge here?" communicating across unequal computer platforms},
	year = {2004},
	issue_date = {December 2004},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {11},
	number = {4},
	issn = {1073-0516},
	url = {https://doi.org/10.1145/1035575.1035579},
	doi = {10.1145/1035575.1035579},
	abstract = {People use personal data assistants in the field to collect data and to communicate with others both in the field and office. The individual in the office invariably has a laptop or a high-end personal workstation and thus, significantly more computing power, more screen real estate, and higher volume input devices, such as a mouse and keyboard. These differences give the high-end user the ability to represent and manipulate collaborative tasks more effectively. It is therefore useful to know what impact these differences have on work performance and work communications. Four different platform combinations involving a PC and a PDA were used to examine the effect of communicating via heterogeneous computer platforms. The PC platform used a mouse, a keyboard, and a 3-dimensional screen display. The PDA platform used a stylus, soft buttons, and a 2-dimensional screen display. A variation of the Tetris wall-building game called Slow Tetris was used as the subjects' collaborative task. A second factor in the experiment was role asymmetry. One subject was arbitrarily put in charge of the task solution in all of the combinations. An analysis of the solution times found that subjects with mixed platforms worked slower than their homogeneous counterparts, that is, a person in charge with a PC worked faster if his partner had a PC. An in-depth analysis of the communication patterns found significant differences in the exchanges between heterogeneous and homogenous combinations. The PC-to-PDA combination (with the person on the PC in charge of the solution) took significantly more time than the PC-to-PC combination. This extra time appears to come from the disadvantage of having a partner on the PDA who is unable to help in solving the problems. The PDA-to-PC combination took approximately the same amount of time as the PDA-to-PDA combination despite having one team member with a better representation. This member was, unfortunately, not in charge of the solution. The PDA-to-PC heterogeneous combination exhibited more direction giving, less one-sided collaboration, and more takeover attempts than any of the other combinations. Overall, roles were maintained in the partnerships except for the person with the PDA directing the person with the PC.},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	month = {dec},
	pages = {407–444},
	numpages = {38},
	keywords = {Collaboration differences, heterogeneous computing, media effects, mobile computing}
}


@article{10.1145/1959022.1959025,
	author = {O'hara, Kenton and Kjeldskov, Jesper and Paay, Jeni},
	title = {Blended interaction spaces for distributed team collaboration},
	year = {2011},
	issue_date = {April 2011},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {18},
	number = {1},
	issn = {1073-0516},
	url = {https://doi.org/10.1145/1959022.1959025},
	doi = {10.1145/1959022.1959025},
	abstract = {In recent years there has been an introduction of sophisticated new video conferencing technologies (e.g., HP Halo, Cisco Telepresence) that have led to enhancements in the collaborative user experience over traditional video conferencing technologies. Traditional video conferencing set-ups often distort the shared spatial properties of action and communication due to screen and camera orientation disparities and other asymmetries. These distortions affect access to the common resources used to mutually organize action and communication. By contrast, new systems, such as Halo, are physically configured to reduce these asymmetries and orientation disparities, thereby minimizing these spatial distortions. By creating appropriate shared spatial geometries, the distributed spaces become “blended” where the spatial geometries of the local space continue coherently across the distributed boundary into the remote site, providing the illusion of a single unified space. Drawing on theories of embodied action and workplace design we discuss the importance of this geometric “blending” of space for distributed collaboration and how this is achieved in systems such as Halo. We then extend these arguments to explore the concept of Blended Interaction Spaces: blended spaces in which interactive groupware is incorporated in ways spatially consistent with the physical geometries of the video-mediated set-up. We illustrate this discussion through a system called BISi that introduces interactive horizontal and vertical multipoint surfaces into a blended video-mediated collaboration space. In presenting this system, we highlight some of the particular challenges of creating these systems arising from the spatial consequences of different interaction mechanisms (e.g., direct touch or remote control) and how they affect movement and spatial configuration of people in these spaces.},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	month = {may},
	articleno = {3},
	numpages = {28},
	keywords = {Collaboration, media spaces, telepresence}
}


@article{10.1145/966930.966934,
	author = {Johnson, Hilary and Hyde, Joanne},
	title = {Towards modeling individual and collaborative construction of jigsaws using task knowledge structures (TKS)},
	year = {2003},
	issue_date = {December 2003},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {10},
	number = {4},
	issn = {1073-0516},
	url = {https://doi.org/10.1145/966930.966934},
	doi = {10.1145/966930.966934},
	abstract = {Recent years have seen an overwhelming interest in how people work together as a group. Both the nature of collaboration and research into how people collaborate is complex and multifaceted, with different research agendas, types of studies, and variations in the behavioral data collected. A better understanding of collaboration is needed in order to be able to make contributions to the design of systems to support collaboration and collaborative tasks. In this article, we combine relevant literature, past research, and a small-scale empirical study of two people individually and collaboratively constructing jigsaws. The objective is to make progress towards the goal of generating extensions to an existing task modeling approach, Task Knowledge Structures. The research described has enabled us to generate requirements for approaches to modeling collaborative tasks and also a set of requirements to be taken into account in the design of a computer-based collaborative virtual jigsaw.},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	month = {dec},
	pages = {339–387},
	numpages = {49},
	keywords = {task analysis, collaborative studies, Modeling}
}


@article{10.1145/210079.210088,
	author = {Greenhalgh, Chris and Benford, Steven},
	title = {MASSIVE: a collaborative virtual environment for teleconferencing},
	year = {1995},
	issue_date = {Sept. 1995},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {2},
	number = {3},
	issn = {1073-0516},
	url = {https://doi.org/10.1145/210079.210088},
	doi = {10.1145/210079.210088},
	abstract = {We describe a prototype virtual reality teleconferencing system called MASSIVE which has been developed as part of our on-going research into collaborative virtual environments. This system allows multiple users to communicate using arbitrary combinations of audio, graphics, and text media over local and wide area networks. Communication is controlled by a so-called spatial model of interaction so that one user's perception of another user is sensitive to their relative positions and orientations. The key concept in this spatial model is the (quantitative) awareness which one object has of another. This is controlled by the observing object's focus and the observed object's nimbus, which describe regions of interest and projection, respectively. Each object's aura defines the total region within which it interacts. This is applied independently in each medium. The system (and the spatial model which it implements) is intended to provide a flexible and natural environment for the spatial mediation of conversation. The model also provides a basis for scaling to relatively large numbers of users. Our design goals include supporting heterogeneity, scalability, spatial mediation, balance of power, and multiple concurrent meetings; MASSIVE meets all of these goals. Our initial experiences show the importance of audio in collaborative VR, and they raise issues about field of view for graphical users, speed of navigation, quality of embodiment, varying perceptions of space, and scalability.},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	month = {sep},
	pages = {239–261},
	numpages = {23},
	keywords = {scalability, CSCW}
}

@inproceedings{10.1145/3613904.3642814,
	author = {Irlitti, Andrew and Latifoglu, Mesut and Hoang, Thuong and Syiem, Brandon Victor and Vetere, Frank},
	title = {Volumetric Hybrid Workspaces: Interactions with Objects in Remote and Co-located Telepresence},
	year = {2024},
	isbn = {9798400703300},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3613904.3642814},
	doi = {10.1145/3613904.3642814},
	abstract = {Volumetric telepresence aims to create a shared space, allowing people in local and remote settings to collaborate seamlessly. Prior telepresence examples typically have asymmetrical designs, with volumetric capture in one location and objects in one format. In this paper, we present a volumetric telepresence mixed reality system that supports real-time, symmetrical, multi-user, partially distributed interactions, using objects in multiple formats, across multiple locations. We align two volumetric environments around a common spatial feature to create a shared workspace for remote and co-located people using objects in three formats: physical, virtual, and volumetric. We conducted a study with 18 participants over 6 sessions, evaluating how telepresence workspaces support spatial coordination and hybrid communication for co-located and remote users undertaking collaborative tasks. Our findings demonstrate the successful integration of remote spaces, effective use of proxemics and deixis to support negotiation, and strategies to manage interactivity in hybrid workspaces.},
	booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
	articleno = {802},
	numpages = {16},
	keywords = {augmented reality, collaboration, mixed reality, partially distributed teams, telepresence, volumetric capture, workspace awareness},
	location = {<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>},
	series = {CHI '24}
}


@inproceedings{10.1145/3613904.3642502,
	author = {Wong, Emily and S\'{a}nchez Esquivel, Juan and Leiva, Germ\'{a}n and Gr\o{}nb\ae{}k, Jens Emil Sloth and Velloso, Eduardo},
	title = {Practice-informed Patterns for Organising Large Groups in Distributed Mixed Reality Collaboration},
	year = {2024},
	isbn = {9798400703300},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3613904.3642502},
	doi = {10.1145/3613904.3642502},
	abstract = {Collaborating across dissimilar, distributed spaces presents numerous challenges for computer-aided spatial communication. Mixed reality (MR) can blend selected surfaces, allowing collaborators to work in blended f-formations (facing formations), even when their workstations are physically misaligned. Since collaboration often involves more than just participant pairs, this research examines how we might scale MR experiences for large-group collaboration. To do so, this study recruited collaboration designers (CDs) to evaluate and reimagine MR for large-scale collaboration. These CDs were engaged in a four-part user study that involved a technology probe, a semi-structured interview, a speculative low-fidelity prototyping activity and a validation session. The outcomes of this paper contribute (1) a set of collaboration design principles to inspire future computer-supported collaborative work, (2) eight collaboration patterns for blended f-formations and collaboration at scale and (3) theoretical implications for f-formations and space-place relationships. As a result, this work creates a blueprint for scaling collaboration across distributed spaces.},
	booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
	articleno = {1030},
	numpages = {18},
	keywords = {collaboration, f-formations, mixed reality, scale, space and place},
	location = {<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>},
	series = {CHI '24}
}


@inproceedings{10.1145/3025453.3025923,
	author = {Berry, Andrew B. L. and Lim, Catherine and Hartzler, Andrea L. and Hirsch, Tad and Wagner, Edward H. and Ludman, Evette and Ralston, James D.},
	title = {How Values Shape Collaboration Between Patients with Multiple Chronic Conditions and Spousal Caregivers},
	year = {2017},
	isbn = {9781450346559},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3025453.3025923},
	doi = {10.1145/3025453.3025923},
	abstract = {Individuals with multiple chronic conditions (MCC) collaborate with spousal caregivers daily to pursue what is most important to their health and well-being. Previous research in human-computer interaction has supported individuals with chronic conditions or their caregivers, but little has supported both as a unit. We conducted a field study with 12 patient-caregiver dyads, all married and living together, to identify partners' values and how they shape collaborative management of MCC. Partners' coinciding values motivated them to empathize with and support each other in the face of challenges related to health and well-being. When their values were asymmetric, they perceived tensions between individual autonomy and their ability to coordinate with their partner. Systems to support partners in this context could help them overcome asymmetric values, but should balance this with support for individual autonomy.},
	booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
	pages = {5257–5270},
	numpages = {14},
	keywords = {caregiver, collaboration, coordination, multiple chronic conditions, patient, self-care, self-management},
	location = {Denver, Colorado, USA},
	series = {CHI '17}
}


@inproceedings{10.1145/1518701.1518784,
	author = {Leshed, Gilly and Perez, Diego and Hancock, Jeffrey T. and Cosley, Dan and Birnholtz, Jeremy and Lee, Soyoung and McLeod, Poppy L. and Gay, Geri},
	title = {Visualizing real-time language-based feedback on teamwork behavior in computer-mediated groups},
	year = {2009},
	isbn = {9781605582467},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1518701.1518784},
	doi = {10.1145/1518701.1518784},
	abstract = {While most collaboration technologies are concerned with supporting particular tasks such as workflows or meetings, many work groups do not have the teamwork skills essential to effective collaboration. One way to improve teamwork is to provide dynamic feedback generated by automated analyses of behavior, such as language use. Such feedback can lead members to reflect on and subsequently improve their collaborative behavior, but might also distract from the task at hand. We have experimented with GroupMeter - a chat-based system that presents visual feedback on team members' language use. Feedback on proportion of agreement words and overall word count was presented using two different designs. When receiving feedback, teams in our study expressed more agreement in their conversations and reported greater focus on language use as compared to when not receiving feedback. This suggests that automated, real-time linguistic feedback can elicit behavioral changes, offering opportunities for future research.},
	booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	pages = {537–546},
	numpages = {10},
	keywords = {cmc, cscw, feedback visualization, linguistic analysis, peripheral displays, teamwork},
	location = {Boston, MA, USA},
	series = {CHI '09}
}


@inproceedings{10.1145/3173574.3173647,
	author = {Homaeian, Leila and Goyal, Nippun and Wallace, James R. and Scott, Stacey D.},
	title = {Group vs Individual: Impact of TOUCH and TILT Cross-Device Interactions on Mixed-Focus Collaboration},
	year = {2018},
	isbn = {9781450356206},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3173574.3173647},
	doi = {10.1145/3173574.3173647},
	abstract = {Cross-device environments (XDEs) have been developed to support a multitude of collaborative activities. Yet, little is known about how different cross-device interaction techniques impact group collaboration, including how their impact on independent and joint work that often occurs during group work. In this work, we explore the impact of two XDE data browsing techniques: TOUCH and TILT. Through a mixed-methods study of a collaborative sensemaking task, we show that TOUCH and TILT have distinct impacts on how groups accomplish, and shift between, independent and joint work. Finally, we reflect on these findings and how they can more generally inform the design of XDEs.},
	booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
	pages = {1–13},
	numpages = {13},
	keywords = {cross-device, mixed-focus collaboration, tilt, touch},
	location = {<conf-loc>, <city>Montreal QC</city>, <country>Canada</country>, </conf-loc>},
	series = {CHI '18}
}


@inproceedings{10.1145/3290605.3300431,
	author = {Teo, Theophilus and Lawrence, Louise and Lee, Gun A. and Billinghurst, Mark and Adcock, Matt},
	title = {Mixed Reality Remote Collaboration Combining 360 Video and 3D Reconstruction},
	year = {2019},
	isbn = {9781450359702},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3290605.3300431},
	doi = {10.1145/3290605.3300431},
	abstract = {Remote Collaboration using Virtual Reality (VR) and Augmented Reality (AR) has recently become a popular way for people from different places to work together. Local workers can collaborate with remote helpers by sharing 360-degree live video or 3D virtual reconstruction of their surroundings. However, each of these techniques has benefits and drawbacks. In this paper we explore mixing 360 video and 3D reconstruction together for remote collaboration, by preserving benefits of both systems while reducing drawbacks of each. We developed a hybrid prototype and conducted user study to compare benefits and problems of using 360 or 3D alone to clarify the needs for mixing the two, and also to evaluate the prototype system. We found participants performed significantly better on collaborative search tasks in 360 and felt higher social presence, yet 3D also showed potential to complement. Participant feedback collected after trying our hybrid system provided directions for improvement.},
	booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
	pages = {1–14},
	numpages = {14},
	keywords = {360 panorama, 3d scene reconstruction, interaction methods, mixed reality, remote collaboration, virtual reality},
	location = {Glasgow, Scotland Uk},
	series = {CHI '19}
}


@inproceedings{10.1145/1357054.1357234,
	author = {M\"{u}ller-Tomfelde, Christian and Schremmer, Claudia},
	title = {Touchers and mousers: commonalities and differences in co-located collaboration with multiple input devices},
	year = {2008},
	isbn = {9781605580111},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1357054.1357234},
	doi = {10.1145/1357054.1357234},
	abstract = {We present new findings on commonalities and differences between touch and mouse input for co-located interaction between teams of two people who know each other. Twenty-two participants were instructed to work as co-located pairs on three sets of two concurrent digital jigsaw puzzles, displayed on a horizontal tabletop that allows for multiple concurrent input devices. They were advised to use their preference for, or any combination of, direct (touch) and indirect (mouse) input device to achieve the goal. We increased the task?s difficulty: In the second and third puzzle task, participants had to discover that pieces were mixed up between the two puzzle stacks. We used this 'hidden task' to trigger spontaneous transitions from individual to collaborative work. Based on a qualitative analysis of individual interaction trajectories of direct and indirect input devices, we discuss patterns of collaboration. This furthers scientific understanding of co-located collaboration with multiple input devices.},
	booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	pages = {1149–1152},
	numpages = {4},
	keywords = {co-located collaboration, direct and indirect input devices, human factors, multiple input devices, tabletop, trajectories},
	location = {Florence, Italy},
	series = {CHI '08}
}


@inproceedings{10.1145/3025453.3025593,
	author = {Lazem, Shaimaa and Jad, Hussein Aly},
	title = {We Play We Learn: Exploring the Value of Digital Educational Games in Rural Egypt},
	year = {2017},
	isbn = {9781450346559},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3025453.3025593},
	doi = {10.1145/3025453.3025593},
	abstract = {The Egyptian education system faces urgent challenges. Proposed governmental reforms tend to focus on increasing access to physical and digital resources. There is insufficient understanding as to how the provided resources are currently used in rural areas. We explored the extent to which digital technology could motivate primary students to collaboratively learn a challenging topic in the National Mathematics Curriculum. We designed and researched a digital game to support memorizing multiplication facts. We used an incentive structure that encouraged individual learning with rewarding teamwork. The game was tested with mixed ability and gender groups of students using the Teams-Game-Tournament collaboration technique. A key outcome was that the students with educationally disadvantaged backgrounds benefited from using the game format. They devised their own play and study strategies. We discuss implications on future designs of the game, and considerations for its integration in Egyptian schools.},
	booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
	pages = {2782–2791},
	numpages = {10},
	keywords = {Egypt, HCI4D, ICT4D, ICTD, collaborative learning, edutainment, game-based learning, games, play},
	location = {Denver, Colorado, USA},
	series = {CHI '17}
}


@inproceedings{10.1145/3025453.3026028,
	author = {Dey, Arindam and Piumsomboon, Thammathip and Lee, Youngho and Billinghurst, Mark},
	title = {Effects of Sharing Physiological States of Players in a Collaborative Virtual Reality Gameplay},
	year = {2017},
	isbn = {9781450346559},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3025453.3026028},
	doi = {10.1145/3025453.3026028},
	abstract = {Interfaces for collaborative tasks, such as multiplayer games can enable more effective and enjoyable collaboration. However, in these systems, the emotional states of the users are often not communicated properly due to their remoteness from one another. In this paper, we investigate the effects of showing emotional states of one collaborator to the other during an immersive Virtual Reality (VR) gameplay experience. We created two collaborative immersive VR games that display the real-time heart-rate of one player to the other. The two different games elicited different emotions, one joyous and the other scary. We tested the effects of visualizing heart-rate feedback in comparison with conditions where such a feedback was absent. The games had significant main effects on the overall emotional experience.},
	booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
	pages = {4045–4056},
	numpages = {12},
	keywords = {collaborative gameplay, emotions, empathic computing, physiological sensors, user study., virtual reality},
	location = {Denver, Colorado, USA},
	series = {CHI '17}
}


@inproceedings{10.1145/3544548.3581041,
	author = {Wu, Yudan and You, Shanhe and Guo, Zixuan and Li, Xiangyang and Zhou, Guyue and Gong, Jiangtao},
	title = {MR.Brick: Designing A Remote Mixed-reality Educational Game System for Promoting Children’s Social &amp; Collaborative Skills},
	year = {2023},
	isbn = {9781450394215},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3544548.3581041},
	doi = {10.1145/3544548.3581041},
	abstract = {Children are one of the groups most influenced by COVID-19-related social distancing, and a lack of contact with peers can limit their opportunities to develop social and collaborative skills. However, remote socialization and collaboration as an alternative approach is still a great challenge for children. This paper presents MR.Brick, a Mixed Reality (MR) educational game system that helps children adapt to remote collaboration. A controlled experimental study involving 24 children aged six to ten was conducted to compare MR.Brick with the traditional video game by measuring their social and collaborative skills and analyzing their multi-modal playing behaviours. The results showed that MR.Brick was more conducive to children’s remote collaboration experience than the traditional video game. Given the lack of training systems designed for children to collaborate remotely, this study may inspire interaction design and educational research in related fields.},
	booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
	articleno = {448},
	numpages = {18},
	keywords = {children, educational game, mixed reality, remote collaboration, social and collaborative skill, tangible user interface},
	location = {<conf-loc>, <city>Hamburg</city>, <country>Germany</country>, </conf-loc>},
	series = {CHI '23}
}


@inproceedings{10.1145/3411764.3445041,
	author = {Sabet, Mehrnaz and Orand, Mania and W. McDonald, David},
	title = {Designing Telepresence Drones to Support Synchronous, Mid-air Remote Collaboration: An Exploratory Study},
	year = {2021},
	isbn = {9781450380966},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3411764.3445041},
	doi = {10.1145/3411764.3445041},
	abstract = {Drones are increasingly used to support humanitarian crises and events that involve dangerous or costly tasks. While drones have great potential for remote collaborative work and aerial telepresence, existing drone technology is limited in its support for synchronous collaboration among multiple remote users. Through three design iterations and evaluations, we prototyped Squadrone, a novel aerial telepresence platform that supports synchronous mid-air collaboration among multiple remote users. We present our design and report results from evaluating our iterations with 13 participants in 3 different collaboration configurations. Our first design iteration validates the basic functionality of the platform. Then, we establish the effectiveness of collaboration using a 360-degree shared aerial display. Finally, we simulate a type of search task in an open environment to see if collaborative telepresence impacts members’ participation. The results validate some initial goals for Squadrone and are used to reflect back on a recent telepresence design framework.},
	booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
	articleno = {450},
	numpages = {17},
	keywords = {Collaborative remote control, Collaborative work, Drones, Quadcopters, Remote collaboration, Telepresence, UAV, User Interface},
	location = {<conf-loc>, <city>Yokohama</city>, <country>Japan</country>, </conf-loc>},
	series = {CHI '21}
}


@inproceedings{10.1145/3613904.3642293,
	author = {Gr\o{}nb\ae{}k, Jens Emil Sloth and S\'{a}nchez Esquivel, Juan and Leiva, Germ\'{a}n and Velloso, Eduardo and Gellersen, Hans and Pfeuffer, Ken},
	title = {Blended Whiteboard: Physicality and Reconfigurability in Remote Mixed Reality Collaboration},
	year = {2024},
	isbn = {9798400703300},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3613904.3642293},
	doi = {10.1145/3613904.3642293},
	abstract = {The whiteboard is essential for collaborative work. To preserve its physicality in remote collaboration, Mixed Reality (MR) can blend real whiteboards across distributed spaces. Going beyond reality, MR can further enable interactions like panning and zooming in a virtually reconfigurable infinite whiteboard. However, this reconfigurability conflicts with the sense of physicality. To address this tension, we introduce Blended Whiteboard, a remote collaborative MR system enabling reconfigurable surface blending across distributed physical whiteboards. Blended Whiteboard supports a unique collaboration style, where users can sketch on their local whiteboards but also reconfigure the blended space to facilitate transitions between loosely and tightly coupled work. We describe design principles inspired by proxemics; supporting users in changing between facing each other and being side-by-side, and switching between navigating the whiteboard synchronously and independently. Our work shows exciting benefits and challenges of combining physicality and reconfigurability in the design of distributed MR whiteboards.},
	booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
	articleno = {798},
	numpages = {16},
	keywords = {3C collaboration model, avatars, f-formations, mixed reality, proxemics, remote collaboration},
	location = {<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>},
	series = {CHI '24}
}


@inproceedings{10.1145/3411764.3445576,
	author = {Gasques, Danilo and Johnson, Janet G. and Sharkey, Tommy and Feng, Yuanyuan and Wang, Ru and Xu, Zhuoqun Robin and Zavala, Enrique and Zhang, Yifei and Xie, Wanze and Zhang, Xinming and Davis, Konrad and Yip, Michael and Weibel, Nadir},
	title = {ARTEMIS: A Collaborative Mixed-Reality System for Immersive Surgical Telementoring},
	year = {2021},
	isbn = {9781450380966},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3411764.3445576},
	doi = {10.1145/3411764.3445576},
	abstract = {Traumatic injuries require timely intervention, but medical expertise is not always available at the patient’s location. Despite recent advances in telecommunications, surgeons still have limited tools to remotely help inexperienced surgeons. Mixed Reality hints at a future where remote collaborators work side-by-side as if co-located; however, we still do not know how current technology can improve remote surgical collaboration. Through role-playing and iterative-prototyping, we identify collaboration practices used by expert surgeons to aid novice surgeons as well as technical requirements to facilitate these practices. We then introduce ARTEMIS, an AR-VR collaboration system that supports these key practices. Through an observational study with two expert surgeons and five novice surgeons operating on cadavers, we find that ARTEMIS supports remote surgical mentoring of novices through synchronous point, draw, and look affordances and asynchronous video clips. Most participants found that ARTEMIS facilitates collaboration despite existing technology limitations explored in this paper.},
	booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
	articleno = {662},
	numpages = {14},
	keywords = {Augmented Reality, Collaboration, Mixed Reality, Surgery, Telementoring, Virtual Reality},
	location = {<conf-loc>, <city>Yokohama</city>, <country>Japan</country>, </conf-loc>},
	series = {CHI '21}
}


@inproceedings{10.1145/2470654.2481312,
	author = {Houben, Steven and Bardram, Jakob E. and Vermeulen, Jo and Luyten, Kris and Coninx, Karin},
	title = {Activity-centric support for ad hoc knowledge work: a case study of co-activity manager},
	year = {2013},
	isbn = {9781450318990},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2470654.2481312},
	doi = {10.1145/2470654.2481312},
	abstract = {Modern knowledge work consists of both individual and highly collaborative activities that are typically composed of a number of configuration, coordination and articulation processes. The desktop interface today, however, provides very little support for these processes and rather forces knowledge workers to adapt to the technology. We introduce co-Activity Manager, an activity-centric desktop system that (i) provides tools for ad hoc dynamic configuration of a desktop working context, (ii) supports both explicit and implicit articulation of ongoing work through a built-in collaboration manager and (iii) provides the means to coordinate and share working context with other users and devices. In this paper, we discuss the activity theory informed design of co-Activity Manager and report on a 14 day field deployment in a multi-disciplinary software development team. The study showed that the activity-centric workspace supports different individual and collaborative work configuration practices and that activity-centric collaboration is a two-phase process consisting of an activity sharing and per-activity coordination phase.},
	booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	pages = {2263–2272},
	numpages = {10},
	keywords = {activity theory, activity-centric computing, collaborative work, desktop interface},
	location = {Paris, France},
	series = {CHI '13}
}


@inproceedings{10.1145/3290605.3300458,
	author = {Piumsomboon, Thammathip and Lee, Gun A. and Irlitti, Andrew and Ens, Barrett and Thomas, Bruce H. and Billinghurst, Mark},
	title = {On the Shoulder of the Giant: A Multi-Scale Mixed Reality Collaboration with 360 Video Sharing and Tangible Interaction},
	year = {2019},
	isbn = {9781450359702},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3290605.3300458},
	doi = {10.1145/3290605.3300458},
	abstract = {We propose a multi-scale Mixed Reality (MR) collaboration between the Giant, a local Augmented Reality user, and the Miniature, a remote Virtual Reality user, in Giant-Miniature Collaboration (GMC). The Miniature is immersed in a 360-video shared by the Giant who can physically manipulate the Miniature through a tangible interface, a combined 360-camera with a 6 DOF tracker. We implemented a prototype system as a proof of concept and conducted a user study (n=24) comprising of four parts comparing: A) two types of virtual representations, B) three levels of Miniature control, C) three levels of 360-video view dependencies, and D) four 360-camera placement positions on the Giant. The results show users prefer a shoulder mounted camera view, while a view frustum with a complimentary avatar is a good visualization for the Miniature virtual representation. From the results, we give design recommendations and demonstrate an example Giant-Miniature Interaction.},
	booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
	pages = {1–17},
	numpages = {17},
	keywords = {live panorama sharing, mixed reality, multi-scale, remote collaboration, tangible user interface, wearable interface},
	location = {Glasgow, Scotland Uk},
	series = {CHI '19}
}


@inproceedings{10.1145/2207676.2208689,
	author = {Bardram, Jakob and Gueddana, Sofiane and Houben, Steven and Nielsen, S\o{}ren},
	title = {ReticularSpaces: activity-based computing support for physically distributed and collaborative smart spaces},
	year = {2012},
	isbn = {9781450310154},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2207676.2208689},
	doi = {10.1145/2207676.2208689},
	abstract = {Smart spaces research focuses on technology for multiple displays and devices for collocated participants. In most approaches, however, users have to cope with heterogeneous interfaces and information organization, as well as a lack of support for collaboration with mobile and remote users outside the smart space. In this paper, we present ReticularSpaces; a multi-display smart space system built on the principles of activity-based computing. The focus of ReticularSpaces is to support: (i) unified interaction with applications and documents through ReticularUI, a novel distributed user interfaces design; (ii) management of the complexity of tasks between users and displays; (iii) mobile users in a local, remote or 'nomadic' settings; and (iv) collaboration among local and remote users. We describe the motivation, design, and architecture of ReticularSpaces, and report from a preliminary feasibility study. The study shows that participants found ReticularSpaces useful and effective, but at the same time reveals new areas for research on smart environments.},
	booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	pages = {2845–2854},
	numpages = {10},
	keywords = {smart spaces, nomadic computing, multiple display environments, distributed user interfaces, collaboration},
	location = {Austin, Texas, USA},
	series = {CHI '12}
}


@inproceedings{10.1145/3411764.3445144,
	author = {Odili Uchidiuno, Judith and Hammer, Jessica and Koedinger, Ken and Ogan, Amy},
	title = {Fostering Equitable Help-Seeking for K-3 Students in Low Income and Rural Contexts},
	year = {2021},
	isbn = {9781450380966},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3411764.3445144},
	doi = {10.1145/3411764.3445144},
	abstract = {Adaptive Collaborative Learning Support (ACLS) systems improve collaboration and learning for students over individual work or collaboration with non-adaptive support. However, many ACLS systems are ill-suited for rural contexts where students often need multiple kinds of support to complete tasks, may speak languages unsupported by the system, and require more than pre-assigned tutor-tutee student pairs for more equitable learning. We designed an intervention that fosters more equitable help-seeking by automatically detecting student struggles and prompts them to seek help from specific peers that can help. We conducted a mixed-methods experimental study with 98 K-3 students in a rural village in Tanzania over a one-month period, evaluating how the system affects student interactions, system engagement, and student learning. Our intervention increased student interactions by almost 4 times compared to the control condition, increased domain knowledge interactions, and propelled students to engage in more cognitively challenging activities.},
	booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
	articleno = {684},
	numpages = {14},
	location = {<conf-loc>, <city>Yokohama</city>, <country>Japan</country>, </conf-loc>},
	series = {CHI '21}
}


@inproceedings{10.1145/3613904.3642435,
	author = {Lakhdhir, Sabrina and Nayar, Chehak and Anderson, Fraser and Fournier, Helene and Holsti, Liisa and Kondratova, Irina and Perin, Charles and Somanath, Sowmya},
	title = {GlucoMaker: Enabling Collaborative Customization of Glucose Monitors},
	year = {2024},
	isbn = {9798400703300},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3613904.3642435},
	doi = {10.1145/3613904.3642435},
	abstract = {Millions of individuals with diabetes use glucose monitors to track blood sugar levels. Research shows that such individuals seek to customize different aspects of their interactions with these devices, including how they engage with, decorate, and wear them. However, it remains challenging to tailor both device form and function to accommodate individual needs. To address this challenge, we introduce GlucoMaker, a system for collaboratively customizing physical design aspects of glucose monitors. Prior to designing GlucoMaker, we conducted a prototyping and focus group study to understand customization preferences and collaboration benefits. GlucoMaker provides individuals with the ability to a) select monitor form and function preferences, b) alter predefined and downloadable digital model files, c) receive feedback on monitor designs from stakeholders, and d) learn technical design aspects. We further demonstrate the versatility and design space of GlucoMaker with three examples of different form and function use cases.},
	booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
	articleno = {127},
	numpages = {21},
	keywords = {collaboration, customization, design, design for health, fabrication, glucose monitors},
	location = {<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>},
	series = {CHI '24}
}


@inproceedings{10.1145/2858036.2858224,
	author = {Zagermann, Johannes and Pfeil, Ulrike and R\"{a}dle, Roman and Jetter, Hans-Christian and Klokmose, Clemens and Reiterer, Harald},
	title = {When Tablets meet Tabletops: The Effect of Tabletop Size on Around-the-Table Collaboration with Personal Tablets},
	year = {2016},
	isbn = {9781450333627},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2858036.2858224},
	doi = {10.1145/2858036.2858224},
	abstract = {Cross-device collaboration with tablets is an increasingly popular topic in HCI. Previous work has shown that tablet-only collaboration can be improved by an additional shared workspace on an interactive tabletop. However, large tabletops are costly and need space, raising the question to what extent the physical size of shared horizontal surfaces really pays off. In order to analyse the suitability of smaller-than-tabletop devices (e.g. tablets) as a low-cost alternative, we studied the effect of the size of a shared horizontal interactive workspace on users' attention, awareness, and efficiency during cross-device collaboration. In our study, 15 groups of two users executed a sensemaking task with two personal tablets (9.7") and a horizontal shared display of varying sizes (10.6", 27", and 55"). Our findings show that different sizes lead to differences in participants' interaction with the tabletop and in the groups' communication styles. To our own surprise we found that larger tabletops do not necessarily improve collaboration or sensemaking results, because they can divert users' attention away from their collaborators and towards the shared display.},
	booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
	pages = {5470–5481},
	numpages = {12},
	keywords = {tablets, tabletops, group work, display size, cross-device interaction},
	location = {San Jose, California, USA},
	series = {CHI '16}
}


@inproceedings{10.1145/3173574.3173632,
	author = {Toxtli, Carlos and Monroy-Hern\'{a}ndez, Andr\'{e}s and Cranshaw, Justin},
	title = {Understanding Chatbot-mediated Task Management},
	year = {2018},
	isbn = {9781450356206},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3173574.3173632},
	doi = {10.1145/3173574.3173632},
	abstract = {Effective task management is essential to successful team collaboration. While the past decade has seen considerable innovation in systems that track and manage group tasks, these innovations have typically been outside of the principal communication channels: email, instant messenger, and group chat. Teams formulate, discuss, refine, assign, and track the progress of their collaborative tasks over electronic communication channels, yet they must leave these channels to update their task-tracking tools, creating a source of friction and inefficiency. To address this problem, we explore how bots might be used to mediate task management for individuals and teams. We deploy a prototype bot to eight different teams of information workers to help them create, assign, and keep track of tasks, all within their main communication channel. We derived seven insights for the design of future bots for coordinating work.},
	booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
	pages = {1–6},
	numpages = {6},
	keywords = {task management, mediated communication, chatbot, bot},
	location = {<conf-loc>, <city>Montreal QC</city>, <country>Canada</country>, </conf-loc>},
	series = {CHI '18}
}


@inproceedings{10.1145/3544548.3581285,
	author = {Ivanyi, Balazs Andras and Tjemsland, Truls Bendik and Tsalidis de Zabala, Christian Vasileios and Toth, Lilla Julia and Dyrholm, Marcus Alexander and Naylor, Scott James and Paradiso, Ann and Lamb, Dwayne and Chudge, Jarnail and Adjorlu, Ali and Serafin, Stefania},
	title = {DuoRhythmo: Design and remote user experience evaluation (UXE) of a collaborative accessible digital musical interface (CADMI) for people with ALS (PALS)},
	year = {2023},
	isbn = {9781450394215},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3544548.3581285},
	doi = {10.1145/3544548.3581285},
	abstract = {We present DuoRhythmo, a collaborative accessible digital musical interface (CADMI) that gives people living with Amyotrophic Lateral Sclerosis (PALS) the experience of remotely and collaboratively creating music in real-time. We designed DuoRhythmo specifically to be utilized for eye tracking and optimized it for head- and computer mouse interaction, as well using a user-centered design approach. Together with five PALS, we completed a mixed-methods evaluation to assess the accessibility of DuoRhythmo. Participants described the CADMI using the Microsoft Desirability Toolkit (MDT) as fun, empowering, accessible, easy to use, engaging, and stimulating and gave an average System Usability Scale (SUS) score of 79.5. We suggest further research on remote collaboration within the field of accessible digital musical instruments (ADMIs) using the term CADMI to explore the positive effects of collaborative music-making on the quality of life of PALS.},
	booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
	articleno = {56},
	numpages = {13},
	keywords = {accessibility, eye tracking, musical co-creation, people living with ALS, remote user experience evaluation, user-centered design},
	location = {<conf-loc>, <city>Hamburg</city>, <country>Germany</country>, </conf-loc>},
	series = {CHI '23}
}


@inproceedings{10.1145/3411764.3445272,
	author = {Alharthi, Sultan A. and LaLone, Nicolas James and Sharma, Hitesh Nidhi and Dolgov, Igor and Toups Dugas, Phoebe O.},
	title = {An Activity Theory Analysis of Search &amp; Rescue Collective Sensemaking and Planning Practices},
	year = {2021},
	isbn = {9781450380966},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3411764.3445272},
	doi = {10.1145/3411764.3445272},
	abstract = {Search and rescue (SAR), a disaster response activity performed to locate and save victims, primarily involves collective sensemaking and planning. SAR responders learn to search and navigate the environment, process information about buildings, and collaboratively plan with maps. We synthesize data from five sources, including field observations and interviews, to understand the informational components of SAR and how information is recorded and communicated. We apply activity theory, uncovering unforeseen factors that are relevant to the design of collaboration systems and training solutions. Through our analysis, we derive design implications to support collaborative information technology and training systems: mixing physical and digital mapping; mixing individual and collective mapping; building for different levels and sources of information; and building for different rules, roles, and activities.},
	booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
	articleno = {146},
	numpages = {20},
	keywords = {training, sensemaking, search and rescue, practice, planning, maps, activity theory.},
	location = {<conf-loc>, <city>Yokohama</city>, <country>Japan</country>, </conf-loc>},
	series = {CHI '21}
}


@inproceedings{10.1145/1978942.1978983,
	author = {Vihavainen, Sami and Mate, Sujeet and Sepp\"{a}l\"{a}, Lassi and Cricri, Francesco and Curcio, Igor D.D.},
	title = {We want more: human-computer collaboration in mobile social video remixing of music concerts},
	year = {2011},
	isbn = {9781450302289},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1978942.1978983},
	doi = {10.1145/1978942.1978983},
	abstract = {Recording and publishing mobile video clips from music concerts is popular. There is a high potential to increase the concert's perceived value when producing video remixes from individual video clips and using them socially. A digital production of a video remix is an interactive process between human and computer. However, it is not clear what the collaboration implications between human and computer are.We present a case study where we compare the processes and products of manual and automatic mobile video remixing. We provide results from the first systematic real world study of the subject. We draw our observations from a user trial where fans recorded mobile video clips during a rock concert.The results reveal issues on heterogeneous interests of the stakeholders, unexpected uses of the raw material, the burden of editing, diverse quality requirements, motivations for remixing, the effect of understanding the logic of automation, and the collaborative use of manual and automatic remixing.},
	booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	pages = {287–296},
	numpages = {10},
	keywords = {video, social, music, mobile, human factors, automation},
	location = {<conf-loc>, <city>Vancouver</city>, <state>BC</state>, <country>Canada</country>, </conf-loc>},
	series = {CHI '11}
}


@inproceedings{10.1145/3411764.3445246,
	author = {Johnson, Janet G and Gasques, Danilo and Sharkey, Tommy and Schmitz, Evan and Weibel, Nadir},
	title = {Do You Really Need to Know Where “That” Is? Enhancing Support for Referencing in Collaborative Mixed Reality Environments},
	year = {2021},
	isbn = {9781450380966},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3411764.3445246},
	doi = {10.1145/3411764.3445246},
	abstract = {Mixed Reality has been shown to enhance remote guidance and is especially well-suited for physical tasks. Conversations during these tasks are heavily anchored around task objects and their spatial relationships in the real world, making referencing - the ability to refer to an object in a way that is understood by others - a crucial process that warrants explicit support in collaborative Mixed Reality systems. This paper presents a 2x2 mixed factorial experiment that explores the effects of providing spatial information and system-generated guidance to task objects. It also investigates the effects of such guidance on the remote collaborator’s need for spatial information. Our results show that guidance increases performance and communication efficiency while reducing the need for spatial information, especially in unfamiliar environments. Our results also demonstrate a reduced need for remote experts to be in immersive environments, making guidance more scalable, and expertise more accessible.},
	booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
	articleno = {514},
	numpages = {14},
	keywords = {Remote Guidance, Referencing, Mixed Reality, Collaboration},
	location = {<conf-loc>, <city>Yokohama</city>, <country>Japan</country>, </conf-loc>},
	series = {CHI '21}
}


@inproceedings{10.1145/3544548.3581444,
	author = {Johnson, Janet G and Sharkey, Tommy and Butarbutar, Iramuali Cynthia and Xiong, Danica and Huang, Ruijie and Sy, Lauren and Weibel, Nadir},
	title = {UnMapped: Leveraging Experts’ Situated Experiences to Ease Remote Guidance in Collaborative Mixed Reality},
	year = {2023},
	isbn = {9781450394215},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3544548.3581444},
	doi = {10.1145/3544548.3581444},
	abstract = {Collaborative Mixed Reality (MR) systems that help extend expertise for physical tasks to remote environments often situate experts in an immersive view of the task environment to bring the collaboration closer to collocated settings. In this paper, we design UnMapped, an alternative interface for remote experts that combines a live 3D view of the active space within the novice’s environment with a static 3D recreation of the expert’s own workspace to leverage their existing spatial memories within it. We evaluate the impact of this approach on single and repeated use of collaborative MR systems for remote guidance through a comparative study. Our results indicate that despite having a limited understanding of the novice’s environment, using an UnMapped interface increased performance and communication efficiency while reducing experts’ task load. We also outline the various affordances of providing remote experts with a familiar and spatially-stable environment to assist novices.},
	booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
	articleno = {878},
	numpages = {20},
	keywords = {Augmented Reality, Mixed Reality, Physical Tasks, Remote Collaboration, Virtual Reality},
	location = {<conf-loc>, <city>Hamburg</city>, <country>Germany</country>, </conf-loc>},
	series = {CHI '23}
}


@inproceedings{10.1145/3313831.3376541,
	author = {Wells, Thomas and Houben, Steven},
	title = {CollabAR  Investigating the Mediating Role of Mobile AR Interfaces on Co-Located Group Collaboration},
	year = {2020},
	isbn = {9781450367080},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3313831.3376541},
	doi = {10.1145/3313831.3376541},
	abstract = {Mobile Augmented Reality (AR) technology is enabling new applications for different domains including architecture, education or medical work. As AR interfaces project digital data, information and models into the real world, it allows for new forms of collaborative work. However, despite the wide availability of AR applications, very little is known about how AR interfaces mediate and shape collaborative practices. This paper presents a study which examines how a mobile AR (M-AR) interface for inspecting and discovering AR models of varying complexity impacts co-located group practices. We contribute new insights into how current mobile AR interfaces impact co-located collaboration. Our results show that M-AR interfaces induce high mental load and frustration, cause a high number of context switches between devices and group discussion, and overall leads to a reduction in group interaction. We present design recommendations for future work focusing on collaborative AR interfaces.},
	booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
	pages = {1–13},
	numpages = {13},
	keywords = {co-located collaboration, mobile augmented reality},
	location = {<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>},
	series = {CHI '20}
}


@inproceedings{10.1145/3613904.3642864,
	author = {Rasch, Julian and Perzl, Florian and Weiss, Yannick and M\"{u}ller, Florian},
	title = {Just Undo It: Exploring Undo Mechanics in Multi-User Virtual Reality},
	year = {2024},
	isbn = {9798400703300},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3613904.3642864},
	doi = {10.1145/3613904.3642864},
	abstract = {With the proliferation of VR and a metaverse on the horizon, many multi-user activities are migrating to the VR world, calling for effective collaboration support. As one key feature, traditional collaborative systems provide users with undo mechanics to reverse errors and other unwanted changes. While undo has been extensively researched in this domain and is now considered industry standard, it is strikingly absent for VR systems in research and industry. This work addresses this research gap by exploring different undo techniques for basic object manipulation in different collaboration modes in VR. We conducted a study involving 32 participants organized in teams of two. Here, we studied users’ performance and preferences in a tower stacking task, varying the available undo techniques and their mode of collaboration. The results suggest that users desire and use undo in VR and that the choice of the undo technique impacts users’ performance and social connection.},
	booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
	articleno = {952},
	numpages = {14},
	keywords = {CSCW, Connectedness, Multi-User, SocialVR, Undo, Virtual Reality},
	location = {<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>},
	series = {CHI '24}
}


@inproceedings{10.1145/642611.642705,
	author = {Ballagas, Rafael and Ringel, Meredith and Stone, Maureen and Borchers, Jan},
	title = {iStuff: a physical user interface toolkit for ubiquitous computing environments},
	year = {2003},
	isbn = {1581136307},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/642611.642705},
	doi = {10.1145/642611.642705},
	abstract = {The iStuff toolkit of physical devices, and the flexible software infrastructure to support it, were designed to simplify the exploration of novel interaction techniques in the post-desktop era of multiple users, devices, systems and applications collaborating in an interactive environment. The toolkit leverages an existing interactive workspace in-frastructure, making it lightweight and platform independent. The supporting software framework includes a dynamically configurable intermediary to simplify the mapping of devices to applications. We describe the iStuff architecture and provide several examples of iStuff, organized into a design space of ubiquitous computing interaction components. The main contribution is a physical toolkit for distributed, heterogeneous environments with run-time retargetable device data flow. We conclude with some insights and experiences derived from using this toolkit and framework to prototype experimental interaction techniques for ubiquitous computing environments.},
	booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	pages = {537–544},
	numpages = {8},
	keywords = {wireless devices, user interface toolkits, ubiquitous computing, tangible user interfaces, programming environments, intermediation, input and interaction technologies, development tools},
	location = {Ft. Lauderdale, Florida, USA},
	series = {CHI '03}
}


@inproceedings{10.1145/642611.642711,
	author = {Brown, Barry and MacColl, Ian and Chalmers, Matthew and Galani, Areti and Randell, Cliff and Steed, Anthony},
	title = {Lessons from the lighthouse: collaboration in a shared mixed reality system},
	year = {2003},
	isbn = {1581136307},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/642611.642711},
	doi = {10.1145/642611.642711},
	abstract = {Museums attract increasing numbers of online visitors along with their conventional physical visitors. This paper presents a study of a mixed reality system that allows web, virtual reality and physical visitors to share a museum visit together in real time. Our system allows visitors to share their location and orientation, communicate over a voice channel, and jointly navigate around a shared information space. Results from a study of 34 users of the system show that visiting with the system was highly interactive and retained many of the attractions of a traditional shared exhibition visit. Specifically, users could navigate together, collaborate around objects and discuss exhibits. These findings have implications for non-museum settings, in particular how location awareness is a powerful resource for collaboration, and how 'hybrid objects' can support collaboration at-a-distance.},
	booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	pages = {577–584},
	numpages = {8},
	keywords = {virtual reality, museum visiting, mixed reality, location-awareness, context-awareness, WWW},
	location = {Ft. Lauderdale, Florida, USA},
	series = {CHI '03}
}


@inproceedings{10.1145/2858036.2858213,
	author = {Martinez-Maldonado, Roberto and Goodyear, Peter and Kay, Judy and Thompson, Kate and Carvalho, Lucila},
	title = {An Actionable Approach to Understand Group Experience in Complex, Multi-surface Spaces},
	year = {2016},
	isbn = {9781450333627},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2858036.2858213},
	doi = {10.1145/2858036.2858213},
	abstract = {There is a steadily growing interest in the design of spaces in which multiple interactive surfaces are present and, in turn, in understanding their role in group activity. However, authentic activities in these multi-surface spaces can be complex. Groups commonly use digital and non-digital artefacts, tools and resources, in varied ways depending on their specific social and epistemic goals. Thus, designing for collaboration in such spaces can be very challenging. Importantly, there is still a lack of agreement on how to approach the analysis of groups' experiences in these heterogeneous spaces. This paper presents an actionable approach that aims to address the complexity of understanding multi-user multi-surface systems. We provide a structure for applying different analytical tools in terms of four closely related dimensions of user activity: the setting, the tasks, the people and the runtime co-configuration. The applicability of our approach is illustrated with six types of analysis of group activity in a multi-surface design studio.},
	booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
	pages = {2062–2074},
	numpages = {13},
	keywords = {ubicomp ecologies, shared-display, multi-surface, horizontal display, groupware, collocated collaboration},
	location = {San Jose, California, USA},
	series = {CHI '16}
}


@inproceedings{10.1145/1240624.1240787,
	author = {Adamczyk, Piotr D. and Twidale, Michael B.},
	title = {Supporting multidisciplinary collaboration: requirements from novel HCI education},
	year = {2007},
	isbn = {9781595935939},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1240624.1240787},
	doi = {10.1145/1240624.1240787},
	abstract = {Many collaborative design tools may suffer from being too generic to address the specific complexities inherent in multidisciplinary collaboration. We provide accounts of several multidisciplinary HCI courses at our institution, elaborating on the challenges student teams face when integrating design practice from a wide variety of disciplines. Of particular interest are the distinct approaches that these multidisciplinary teams adopt that differ from more common forms of collaborative design. We suggest reasons for the poor rate of adoption of existing collaborative support tools and outline specific suggestions for directions in both ethnographic studies of multidisciplinary collaboration and collaborative systems design.},
	booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	pages = {1073–1076},
	numpages = {4},
	keywords = {social bookmarking, multidisciplinary collaboration, low fidelity prototyping, design tools, design education},
	location = {<conf-loc>, <city>San Jose</city>, <state>California</state>, <country>USA</country>, </conf-loc>},
	series = {CHI '07}
}


@inproceedings{10.1145/3313831.3376550,
	author = {Bai, Huidong and Sasikumar, Prasanth and Yang, Jing and Billinghurst, Mark},
	title = {A User Study on Mixed Reality Remote Collaboration with Eye Gaze and Hand Gesture Sharing},
	year = {2020},
	isbn = {9781450367080},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3313831.3376550},
	doi = {10.1145/3313831.3376550},
	abstract = {Supporting natural communication cues is critical for people to work together remotely and face-to-face. In this paper we present a Mixed Reality (MR) remote collaboration system that enables a local worker to share a live 3D panorama of his/her surroundings with a remote expert. The remote expert can also share task instructions back to the local worker using visual cues in addition to verbal communication. We conducted a user study to investigate how sharing augmented gaze and gesture cues from the remote expert to the local worker could affect the overall collaboration performance and user experience. We found that by combing gaze and gesture cues, our remote collaboration system could provide a significantly stronger sense of co-presence for both the local and remote users than using the gaze cue alone. The combined cues were also rated significantly higher than the gaze in terms of ease of conveying spatial actions.},
	booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
	pages = {1–13},
	numpages = {13},
	keywords = {3d panorama, augmented reality, eye gaze, hand gesture, mixed reality, remote collaboration, scene reconstruction, virtual reality},
	location = {<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>},
	series = {CHI '20}
}


@inproceedings{10.1145/2207676.2207685,
	author = {Kreitmayer, Stefan and Rogers, Yvonne and Laney, Robin and Peake, Stephen},
	title = {From participatory to contributory simulations: changing the game in the classroom},
	year = {2012},
	isbn = {9781450310154},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2207676.2207685},
	doi = {10.1145/2207676.2207685},
	abstract = {There is much potential for supporting collaborative learning with interactive computer simulations in formal education and professional training. A number have been developed for single user and remote interaction. In contrast, our research is concerned with how such learning activities can be designed to fit into co-located large group settings, such as whole classrooms. This paper reports on the iterative design process and two in-the-wild evaluations of the 4Decades game, which was developed for a whole classroom of students to engage with a climate simulation. The system allows students to play and change the rules of the simulation, thereby enabling them to be actively engaged at different levels. The notion of Contributory Simulations is proposed as an instructional model that empowers groups to make informed, critical changes to the underlying scientific model. We discuss how large-group collaboration was supported through constraining an ecology of shared devices and public displays.},
	booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	pages = {49–58},
	numpages = {10},
	keywords = {ubiquitous technologies, tablets, serious games, participatory simulations, contributory simulations, collaborative learning, ambient displays},
	location = {Austin, Texas, USA},
	series = {CHI '12}
}


@inproceedings{10.1145/3613904.3641924,
	author = {Szymanski, Annalisa and Wimer, Brianna L and Anuyah, Oghenemaro and Eicher-Miller, Heather A and Metoyer, Ronald A},
	title = {Integrating Expertise in LLMs: Crafting a Customized Nutrition Assistant with Refined Template Instructions},
	year = {2024},
	isbn = {9798400703300},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3613904.3641924},
	doi = {10.1145/3613904.3641924},
	abstract = {Large Language Models (LLMs) have the potential to contribute to the fields of nutrition and dietetics in generating food product explanations that facilitate informed food selections. However, the extent to which these models offer effective and accurate information remains unverified. In collaboration with registered dietitians (RDs), we evaluate the strengths and weaknesses of LLMs in providing accurate and personalized nutrition information. Through a mixed-methods approach, RDs validated GPT-4 outputs at various levels of prompt specificity, which led to the development of design guidelines used to prompt LLMs for nutrition information. We tested these guidelines by creating a GPT prototype, The Food Product Nutrition Assistant, tailored for food product explanations. This prototype was refined and evaluated in focus groups with RDs. We find that the implementation of these dietitian-reviewed template instructions enhance the generation of detailed food product descriptions and tailored nutrition information.},
	booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
	articleno = {992},
	numpages = {22},
	keywords = {Artificial Intelligence, Food Recommendations, Large Language Models},
	location = {<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>},
	series = {CHI '24}
}


@inproceedings{10.1145/3173574.3173758,
	author = {Park, Seonwook and Gebhardt, Christoph and R\"{a}dle, Roman and Feit, Anna Maria and Vrzakova, Hana and Dayama, Niraj Ramesh and Yeo, Hui-Shyong and Klokmose, Clemens N. and Quigley, Aaron and Oulasvirta, Antti and Hilliges, Otmar},
	title = {AdaM: Adapting Multi-User Interfaces for Collaborative Environments in Real-Time},
	year = {2018},
	isbn = {9781450356206},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3173574.3173758},
	doi = {10.1145/3173574.3173758},
	abstract = {Developing cross-device multi-user interfaces (UIs) is a challenging problem. There are numerous ways in which content and interactivity can be distributed. However, good solutions must consider multiple users, their roles, their preferences and access rights, as well as device capabilities. Manual and rule-based solutions are tedious to create and do not scale to larger problems nor do they adapt to dynamic changes, such as users leaving or joining an activity. In this paper, we cast the problem of UI distribution as an assignment problem and propose to solve it using combinatorial optimization. We present a mixed integer programming formulation which allows real-time applications in dynamically changing collaborative settings. It optimizes the allocation of UI elements based on device capabilities, user roles, preferences, and access rights. We present a proof-of-concept designer-in-the-loop tool, allowing for quick solution exploration. Finally, we compare our approach to traditional paper prototyping in a lab study.},
	booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
	pages = {1–14},
	numpages = {14},
	keywords = {ui adaptation, optimization, distributed user interface, cross-device interaction},
	location = {<conf-loc>, <city>Montreal QC</city>, <country>Canada</country>, </conf-loc>},
	series = {CHI '18}
}


@inproceedings{10.1145/1357054.1357102,
	author = {Danis, Catalina M. and Viegas, Fernanda B. and Wattenberg, Martin and Kriss, Jesse},
	title = {Your place or mine? visualization as a community component},
	year = {2008},
	isbn = {9781605580111},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1357054.1357102},
	doi = {10.1145/1357054.1357102},
	abstract = {Many Eyes is a web site that provides collaborative visualization services, allowing users to upload data sets, visualize them, and comment on each other's visualizations. This paper describes a first interview-based study of Many Eyes users, which sheds light on user motivation for creating public visualizations. Users talked about data for many reasons, from scientific research to political advocacy to hobbies. One consistent theme across these different scenarios is the use of visualizations in communication and collaborative practices. Collaboration and conversation, however, often took place outside the site, leaving no traces on Many Eyes itself. In other words, despite spurring significant social activity, Many Eyes is not so much an online community as a "community component" which users insert into pre-existing online social systems.},
	booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	pages = {275–284},
	numpages = {10},
	keywords = {visualization, social data analysis, distributed community, communication},
	location = {Florence, Italy},
	series = {CHI '08}
}


@inproceedings{10.1145/3025453.3025793,
	author = {Evans, Abigail C. and Davis, Katie and Fogarty, James and Wobbrock, Jacob O.},
	title = {Group Touch: Distinguishing Tabletop Users in Group Settings via Statistical Modeling of Touch Pairs},
	year = {2017},
	isbn = {9781450346559},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3025453.3025793},
	doi = {10.1145/3025453.3025793},
	abstract = {We present Group Touch, a method for distinguishing among multiple users simultaneously interacting with a tabletop computer using only the touch information supplied by the device. Rather than tracking individual users for the duration of an activity, Group Touch distinguishes users from each other by modeling whether an interaction with the tabletop corresponds to either: (1) a new user, or (2) a change in users currently interacting with the tabletop. This reframing of the challenge as distinguishing users rather than tracking and identifying them allows Group Touch to support multi-user collaboration in real-world settings without custom instrumentation. Specifically, Group Touch examines pairs of touches and uses the difference in orientation, distance, and time between two touches to determine whether the same person performed both touches in the pair. Validated with field data from high-school students in a classroom setting, Group Touch distinguishes among users "in the wild" with a mean accuracy of 92.92% (SD=3.94%). Group Touch can imbue collaborative touch applications in real-world settings with the ability to distinguish among multiple users.},
	booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
	pages = {35–47},
	numpages = {13},
	keywords = {tabletop, modeling, distinguishing users, "in the wild"},
	location = {Denver, Colorado, USA},
	series = {CHI '17}
}


@inproceedings{10.1145/3613904.3642857,
	author = {Patnaik, Biswaksen and Peng, Huaishu and Elmqvist, Niklas},
	title = {VisTorch: Interacting with Situated Visualizations using Handheld Projectors},
	year = {2024},
	isbn = {9798400703300},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3613904.3642857},
	doi = {10.1145/3613904.3642857},
	abstract = {Spatial data is best analyzed in situ, but existing mixed reality technologies can be bulky, expensive, or unsuitable for collaboration. We present VisTorch: a handheld device for projected situated analytics consisting of a pico-projector, a multi-spectrum camera, and a touch surface. VisTorch enables viewing charts situated in physical space by simply pointing the device at a surface to reveal visualizations in that location. We evaluated the approach using both a user study and an expert review. In the former, we asked 20 participants to first organize charts in space and then refer to these charts to answer questions. We observed three spatial and one temporal pattern in participant analyses. In the latter, four experts—a museum designer, a statistical software developer, a theater stage designer, and an environmental educator—utilized VisTorch to derive practical usage scenarios. Results from our study showcase the utility of situated visualizations for memory and recall.},
	booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
	articleno = {208},
	numpages = {13},
	keywords = {Ubiquitous analytics, augmented reality, immersive analytics, situated visualization.},
	location = {<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>},
	series = {CHI '24}
}


@inproceedings{10.1145/3544548.3581274,
	author = {Bala, Paulo and Sanches, Pedro and Ces\'{a}rio, Vanessa and Le\~{a}o, Sarah and Rodrigues, Catarina and Nunes, Nuno Jardim and Nisi, Valentina},
	title = {Towards Critical Heritage in the wild: Analysing Discomfort through Collaborative Autoethnography},
	year = {2023},
	isbn = {9781450394215},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3544548.3581274},
	doi = {10.1145/3544548.3581274},
	abstract = {As we engaged in designing digital interventions for intercultural dialogues around public cultural heritage sites, we saw an opportunity to surface multiple interpretations and points of view of history and shine a critical lens on current societal issues. To do so, we present the results of a collaborative auto-ethnography of alternative tours accompanied by intercultural guides, to explore sensory and embodied engagements with cultural heritage sites in a southern European capital. By focusing on the differences in how we experienced the heritage sites, we analyse the duality of discomfort, a common concept in HCI, in that it can both be deployed as a resource for designing systems that can transform people’s understanding of history or it can be a hindrance for engagement, having an unequal effect on individuals.},
	booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
	articleno = {771},
	numpages = {19},
	keywords = {cultural heritage, ethnography, intercultural dialogues},
	location = {<conf-loc>, <city>Hamburg</city>, <country>Germany</country>, </conf-loc>},
	series = {CHI '23}
}


@inproceedings{10.1145/3613904.3642945,
	author = {Sakashita, Mose and Thoravi Kumaravel, Balasaravanan and Marquardt, Nicolai and Wilson, Andrew David},
	title = {SharedNeRF: Leveraging Photorealistic and View-dependent Rendering for Real-time and Remote Collaboration},
	year = {2024},
	isbn = {9798400703300},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3613904.3642945},
	doi = {10.1145/3613904.3642945},
	abstract = {Collaborating around physical objects necessitates examining different aspects of design or hardware in detail when reviewing or inspecting physical artifacts or prototypes. When collaborators are remote, coordinating the sharing of views of their physical environment becomes challenging. Video-conferencing tools often do not provide the desired viewpoints for a remote viewer. While RGB-D cameras offer 3D views, they lack the necessary fidelity. We introduce SharedNeRF, designed to enhance synchronous remote collaboration by leveraging the photorealistic and view-dependent nature of Neural Radiance Field (NeRF). The system complements the higher visual quality of the NeRF rendering with the instantaneity of a point cloud and combines them through carefully accommodating the dynamic elements within the shared space, such as hand gestures and moving objects. The system employs a head-mounted camera for data collection, creating a volumetric task space on the fly and updating it as the task space changes. In our preliminary study, participants successfully completed a flower arrangement task, benefiting from SharedNeRF’s ability to render the space in high fidelity from various viewpoints.},
	booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
	articleno = {675},
	numpages = {14},
	keywords = {Collaboration, NeRF, Spatial Interfaces;},
	location = {<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>},
	series = {CHI '24}
}


@inproceedings{10.1145/3491102.3501936,
	author = {Liao, Mengqi and Sundar, S. Shyam and B. Walther, Joseph},
	title = {User Trust in Recommendation Systems: A comparison of Content-Based, Collaborative and Demographic Filtering},
	year = {2022},
	isbn = {9781450391573},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3491102.3501936},
	doi = {10.1145/3491102.3501936},
	abstract = {Three of the most common approaches used in recommender systems are content-based filtering (matching users’ preferences with products’ characteristics), collaborative filtering (matching users with similar preferences), and demographic filtering (catering to users based on demographic characteristics). Do users’ intuitions lead them to trust one of these approaches over others, independent of the actual operations of these different systems? Does their faith in one type or another depend on the quality of the recommendation, rather than how the recommendation appears to have been derived? We conducted an empirical study with a prototype of a movie recommender system to find out. A 3 (Ostensible Recommender Type: Content vs. Collaborative vs. Demographic Filtering) x 2 (Recommendation Quality: Good vs. Bad) experiment (N=226) investigated how users evaluate systems and attribute responsibility for the recommendations they receive. We found that users trust systems that use collaborative filtering more, regardless of the system's performance. They think that they themselves are responsible for good recommendations but that the system is responsible for bad recommendations (reflecting a self-serving bias). Theoretical insights, design implications and practical solutions for the cold start problem are discussed.},
	booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
	articleno = {486},
	numpages = {14},
	keywords = {User Experience Design, Personalization, Empirical study that tells us about how people use a system},
	location = {<conf-loc>, <city>New Orleans</city>, <state>LA</state>, <country>USA</country>, </conf-loc>},
	series = {CHI '22}
}


@inproceedings{10.1145/3173574.3173973,
	author = {Nouwens, Midas and Klokmose, Clemens Nylandsted},
	title = {The Application and Its Consequences for Non-Standard Knowledge Work},
	year = {2018},
	isbn = {9781450356206},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3173574.3173973},
	doi = {10.1145/3173574.3173973},
	abstract = {Application-centric computing dominates human-computer interactions, yet the concept of an application is ambiguous and the impact of its ubiquity underexplored. We unpack "the application" through the lens of non-standard knowledge work: freelance, self-employed, and fixed-term contract workers who create knowledge in collaboration with a wide variety of stakeholders on a per-project basis. Based on interviews with fourteen participants we describe how: i) their economic value is intertwined with data and skills related to specific applications; ii) their access to this value is systematically jeopardised in collaboration due to the different application practices, preferences, and proficiencies of other stakeholders; and iii) they mitigate the costs of this compromise through cross-application collaboration strategies. We trace these experiences to common characteristics of applications, such as update processes, interface symmetries, application-document relationships, and operating system and hardware dependencies. By empirically and analytically focusing on "the application", we reveal the implications of the current application-centric computing paradigm and discuss how variations within this model create qualitatively different human-computer interactions.},
	booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
	pages = {1–12},
	numpages = {12},
	keywords = {non-standard work, knowledge work, application-centric computing, application paradigm},
	location = {<conf-loc>, <city>Montreal QC</city>, <country>Canada</country>, </conf-loc>},
	series = {CHI '18}
}


@inproceedings{10.1145/3491102.3517526,
	author = {Belghith, Yasmine and Venkatagiri, Sukrit and Luther, Kurt},
	title = {Compete, Collaborate, Investigate: Exploring the Social Structures of Open Source Intelligence Investigations},
	year = {2022},
	isbn = {9781450391573},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3491102.3517526},
	doi = {10.1145/3491102.3517526},
	abstract = {Online investigations are increasingly conducted by individuals with diverse skill levels and experiences, with mixed results. Novice investigations often result in vigilantism or doxxing, while expert investigations have greater success rates and fewer mishaps. Many of these experts are involved in a community of practice known as Open Source Intelligence (OSINT), with an ethos and set of techniques for conducting investigations using only publicly available data. Through semi-structured interviews with 14 expert OSINT investigators from nine different organizations, we examine the social dynamics of this community, including the collaboration and competition patterns that underlie their investigations. We also describe investigators’ use of and challenges with existing OSINT tools, and implications for the design of social computing systems to better support crowdsourced investigations.},
	booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
	articleno = {129},
	numpages = {18},
	keywords = {open source intelligence, investigation, experts, crowdsourcing, competition, collaboration, OSINT},
	location = {<conf-loc>, <city>New Orleans</city>, <state>LA</state>, <country>USA</country>, </conf-loc>},
	series = {CHI '22}
}


@inproceedings{10.1145/1978942.1979201,
	author = {Lucero, Andr\'{e}s and Holopainen, Jussi and Jokela, Tero},
	title = {Pass-them-around: collaborative use of mobile phones for photo sharing},
	year = {2011},
	isbn = {9781450302289},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1978942.1979201},
	doi = {10.1145/1978942.1979201},
	abstract = {In this paper we explore shared collocated interactions with mobile phones. We introduce a phone-based application that allows a small group of collocated people to share photos using the metaphor of passing paper photos around. The prototype encourages people to share their devices and use them interchangeably while discussing photos face-to-face. The prototype supports ad-hoc photo sharing in different contexts by taking into account the spatial arrangement of users around a table, measured with sensors embedded in their mobile phones. Our evaluations show that people are willing to share and connect their mobile phones to engage in collaborative interactions. Participants were able to easily share their collections of photos using our proposed interaction techniques.},
	booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	pages = {1787–1796},
	numpages = {10},
	keywords = {photo sharing., handheld devices, collocated interaction},
	location = {<conf-loc>, <city>Vancouver</city>, <state>BC</state>, <country>Canada</country>, </conf-loc>},
	series = {CHI '11}
}


@inproceedings{10.1145/642611.642714,
	author = {McDonald, David W.},
	title = {Recommending collaboration with social networks: a comparative evaluation},
	year = {2003},
	isbn = {1581136307},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/642611.642714},
	doi = {10.1145/642611.642714},
	abstract = {Studies of information seeking and workplace collaboration often find that social relationships are a strong factor in determining who collaborates with whom. Social networks provide one means of visualizing existing and potential interaction in organizational settings. Groupware designers are using social networks to make systems more sensitive to social situations and guide users toward effective collaborations. Yet, the implications of embedding social networks in systems have not been systematically studied. This paper details an evaluation of two different social networks used in a system to recommend individuals for possible collaboration. The system matches people looking for expertise with individuals likely to have expertise. The effectiveness of social networks for matching individuals is evaluated and compared. One finding is that social networks embedded into systems do not match individuals' perceptions of their personal social network. This finding and others raise issues for the use of social networks in groupware. Based on the evaluation results, several design considerations are discussed.},
	booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	pages = {593–600},
	numpages = {8},
	keywords = {social networks, recommender systems, information seeking, expertise locating},
	location = {Ft. Lauderdale, Florida, USA},
	series = {CHI '03}
}


@inproceedings{10.1145/1753326.1753516,
	author = {Forlizzi, Jodi and Barley, William C. and Seder, Thomas},
	title = {Where should i turn: moving from individual to collaborative navigation strategies to inform the interaction design of future navigation systems},
	year = {2010},
	isbn = {9781605589299},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1753326.1753516},
	doi = {10.1145/1753326.1753516},
	abstract = {The design of in-vehicle navigation systems fails to take into account the social nature of driving and automobile navigation. In this paper, we consider navigation as a social activity among drivers and navigators to improve design of such systems. We explore the implications of moving from a map-centered, individually-focused design paradigm to one based upon collaborative human interaction during the navigation task. We conducted a qualitative interaction design study of navigation among three types of teams: parents and their teenage children, couples, and unacquainted individuals. We found that collaboration varied among these different teams, and was influenced by social role, as well as the task role of driver or navigator. We also found that patterns of prompts, maneuvers, and confirmations varied among the three teams. We identify overarching practices that differ greatly from the literature on individual navigation. From these discoveries, we present design implications that can be used to inform future navigation systems.},
	booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	pages = {1261–1270},
	numpages = {10},
	keywords = {interaction design, in-car navigation, gps systems},
	location = {Atlanta, Georgia, USA},
	series = {CHI '10}
}


@inproceedings{10.1145/3341215.3358246,
	author = {Smilovitch, Michael and Lachman, Richard},
	title = {BirdQuestVR: A Cross-Platform Asymmetric Communication Game},
	year = {2019},
	isbn = {9781450368711},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3341215.3358246},
	doi = {10.1145/3341215.3358246},
	abstract = {BirdQuestVR is a cross-platform asymmetric communication game between one player in Virtual Reality and another on a mobile device. The game explores asymmetric co-operative gaming in a shared physical space, taking the physical surroundings of the VR user into account in its design. Asymmetric games feature different rules, abilities, or objectives for different players, generating unique and nuanced game experiences. Multiplayer asymmetric games in particular have been shown to increase teamwork and a collaborative mindset even after a play session has ended. Asymmetric design is commonplace in both digital and analog games but has yet to see widespread adoption in the emerging Virtual Reality (VR) gaming space. BirdQuestVR seeks to leverage the affordances of current consumer-grade VR headsets to build asymmetric gameplay around communication, embodied performance, and physical humour.},
	booktitle = {Extended Abstracts of the Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts},
	pages = {307–313},
	numpages = {7},
	keywords = {asymmetric, avatar embodiment, cross-platform, social play, virtual reality},
	location = {Barcelona, Spain},
	series = {CHI PLAY '19 Extended Abstracts}
}

@inproceedings{10.1145/2046396.2046410,
	author = {Goldman, Max},
	title = {Role-based interfaces for collaborative software development},
	year = {2011},
	isbn = {9781450310147},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2046396.2046410},
	doi = {10.1145/2046396.2046410},
	abstract = {Real-time collaboration between multiple simultaneous contributors to a shared document is full of both opportunities and pitfalls, as evidenced by decades of research and industry work in computer-supported cooperative work. In the domain of software engineering, collaboration is still generally achieved either via shared use of a single computer (e.g. pair programming) or with version control (and manual pushing and pulling of changes). By examining and designing for the different roles collaborating programmers play when working synchronously together, we can build real-time collaborative programming systems that make their collaboration more effective. And beyond simple shared editing, we can provide asymmetric, role-specific interfaces on their shared task. Collabode is a web-based IDE for collaborative programming with simultaneous editors that, along with several novel models for closely-collaborative software development, explores the potential of real-time cooperative programming.},
	booktitle = {Proceedings of the 24th Annual ACM Symposium Adjunct on User Interface Software and Technology},
	pages = {23–26},
	numpages = {4},
	keywords = {collaboration, crowdsourcing, pair programming, software development},
	location = {Santa Barbara, California, USA},
	series = {UIST '11 Adjunct}
}


@inproceedings{10.1145/3379337.3415827,
	author = {Thoravi Kumaravel, Balasaravanan and Nguyen, Cuong and DiVerdi, Stephen and Hartmann, Bjoern},
	title = {TransceiVR: Bridging Asymmetrical Communication Between VR Users and External Collaborators},
	year = {2020},
	isbn = {9781450375146},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3379337.3415827},
	doi = {10.1145/3379337.3415827},
	abstract = {Virtual Reality (VR) users often need to work with other users, who observe them outside of VR using an external display. Communication between them is difficult; the VR user cannot see the external user's gestures, and the external user cannot see VR scene elements outside of the VR user's view. We carried out formative interviews with experts to understand these asymmetrical interactions and identify their goals and challenges. From this, we identify high-level system design goals to facilitate asymmetrical interactions and a corresponding space of implementation approaches based on the level of programmatic access to a VR application. We present TransceiVR, a system that utilizes VR platform APIs to enable asymmetric communication interfaces for third-party applications without requiring source code access. TransceiVR allows external users to explore the VR scene spatially or temporally, to annotate elements in the VR scene at correct depths, and to discuss via a shared static virtual display. An initial co-located user evaluation with 10 pairs shows that our system makes asymmetric collaborations in VR more effective and successful in terms of task time, error rate, and task load index. An informal evaluation with a remote expert gives additional insight on utility of features for real world tasks.},
	booktitle = {Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology},
	pages = {182–195},
	numpages = {14},
	keywords = {asymmetric interactions, collaboration, virtual reality},
	location = {Virtual Event, USA},
	series = {UIST '20}
}

@inproceedings{10.1145/3379337.3415843,
	author = {Jansen, Pascal and Fischbach, Fabian and Gugenheimer, Jan and Stemasov, Evgeny and Frommel, Julian and Rukzio, Enrico},
	title = {ShARe: Enabling Co-Located Asymmetric Multi-User Interaction for Augmented Reality Head-Mounted Displays},
	year = {2020},
	isbn = {9781450375146},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3379337.3415843},
	doi = {10.1145/3379337.3415843},
	abstract = {Head-Mounted Displays (HMDs) are the dominant form of enabling Virtual Reality (VR) and Augmented Reality (AR) for personal use. One of the biggest challenges of HMDs is the exclusion of people in the vicinity, such as friends or family. While recent research on asymmetric interaction for VR HMDs has contributed to solving this problem in the VR domain, AR HMDs come with similar but also different problems, such as conflicting information in visualization through the HMD and projection. In this work, we propose ShARe, a modified AR HMD combined with a projector that can display augmented content onto planar surfaces to include the outside users (non-HMD users). To combat the challenge of conflicting visualization between augmented and projected content, ShARe visually aligns the content presented through the AR HMD with the projected content using an internal calibration procedure and a servo motor. Using marker tracking, non-HMD users are able to interact with the projected content using touch and gestures. To further explore the arising design space, we implemented three types of applications (collaborative game, competitive game, and external visualization). ShARe is a proof-of-concept system that showcases how AR HMDs can facilitate interaction with outside users to combat exclusion and instead foster rich, enjoyable social interactions.},
	booktitle = {Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology},
	pages = {459–471},
	numpages = {13},
	keywords = {asymmetric interaction, augmented reality, co-located, head-mounted displays, mixed reality},
	location = {Virtual Event, USA},
	series = {UIST '20}
}


@inproceedings{10.1145/3266037.3271643,
	author = {Elvezio, Carmine and Ling, Frank and Liu, Jen-Shuo and Feiner, Steven},
	title = {Collaborative Virtual Reality for Low-Latency Interaction},
	year = {2018},
	isbn = {9781450359498},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3266037.3271643},
	doi = {10.1145/3266037.3271643},
	abstract = {In collaborative virtual environments, users must often perform tasks requiring coordinated action between multiple parties. Some cases are symmetric, in which users work together on equal footing, while others are asymmetric, in which one user may have more experience or capabilities than another (e.g., one may guide another in completing a task). We present a multi-user virtual reality system that supports interactions of both these types. Two collaborating users, whether co-located or remote, simultaneously manipulate the same virtual objects in a physics simulation, in tasks that require low latency networking to perform successfully. We are currently applying this approach to motor rehabilitation, in which a therapist and patient work together.},
	booktitle = {Adjunct Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology},
	pages = {179–181},
	numpages = {3},
	keywords = {collaboration, games, rehabilitation, virtual reality},
	location = {Berlin, Germany},
	series = {UIST '18 Adjunct}
}

@inproceedings{10.1145/3474349.3480211,
	author = {Chen, Bo-Han and Wong, Sai-Keung and Chang, Wei-Che and Ping-Hao Fan, Roy},
	title = {Towards Social Interaction between 1st and 2nd Person Perspectives on Bodily Play},
	year = {2021},
	isbn = {9781450386555},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3474349.3480211},
	doi = {10.1145/3474349.3480211},
	abstract = {Bodily play, which is a productive social interaction for bonding social relationships, has positive impacts on self-efficacy, acute cognitive benefit, and emotion. However, most bodily play encourages players to enjoy their own experiences. There are limited researches on sharing players' perspectives to enhance players' empathy for understanding others. Thus, we propose an asymmetric two-person game in an immersive environment. This bodily play, which supports perspective-taking via the integration with the first- and second-perspectives, has a collaborative interface that allows users to share their physiological and emotional perspectives. Initial testing of the system shows that players can not only understand well the feeling and problems encountered by each other through sharing perspectives and information but also increases the social closeness of players and stimulates empathy after the interplay.},
	booktitle = {Adjunct Proceedings of the 34th Annual ACM Symposium on User Interface Software and Technology},
	pages = {1–3},
	numpages = {3},
	keywords = {Bodily play, collaborative exertion game, empathy, person perspectives, social interaction, virtual reality},
	location = {Virtual Event, USA},
	series = {UIST '21 Adjunct}
}


@inproceedings{10.1145/1866029.1866050,
	author = {Reilly, Derek F. and Rouzati, Hafez and Wu, Andy and Hwang, Jee Yeon and Brudvik, Jeremy and Edwards, W. Keith},
	title = {TwinSpace: an infrastructure for cross-reality team spaces},
	year = {2010},
	isbn = {9781450302715},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1866029.1866050},
	doi = {10.1145/1866029.1866050},
	abstract = {We introduce TwinSpace, a flexible software infrastructure for combining interactive workspaces and collaborative virtual worlds. Its design is grounded in the need to support deep connectivity and flexible mappings between virtual and real spaces to effectively support collaboration. This is achieved through a robust connectivity layer linking heterogeneous collections of physical and virtual devices and services, and a centralized service to manage and control mappings between physical and virtual. In this paper we motivate and present the architecture of TwinSpace, discuss our experiences and lessons learned in building a generic framework for collaborative cross-reality, and illustrate the architecture using two implemented examples that highlight its flexibility and range, and its support for rapid prototyping.},
	booktitle = {Proceedings of the 23nd Annual ACM Symposium on User Interface Software and Technology},
	pages = {119–128},
	numpages = {10},
	keywords = {collaborative virtual environment, cross-reality, interactive room, ontology, rdf, smart room, tuplespace, virtual world},
	location = {New York, New York, USA},
	series = {UIST '10}
}


@inproceedings{10.1145/3311350.3347152,
	author = {Zhou, Zhuoming and M\'{a}rquez Segura, Elena and Duval, Jared and John, Michael and Isbister, Katherine},
	title = {Astaire: A Collaborative Mixed Reality Dance Game for Collocated Players},
	year = {2019},
	isbn = {9781450366885},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3311350.3347152},
	doi = {10.1145/3311350.3347152},
	abstract = {Despite the growth of Virtual Reality (VR), the design space of collocated social play in VR remains narrow. Here we present Astaire, a collaborative hybrid VR dance game for two players sharing an HTC Vive VR system. The game resulted from a design research process using embodied design methods, and drawing upon concepts in HCI and Play Design, including social affordances, and asymmetric and interdependent play. Here we present insights from a study playtesting Astaire alongside two VR games that inspired ours: Keep Talking and Nobody Explodes (KTNE), and Audioshield. We examined players' and spectators' enjoyment, and interpersonal relationships, which were self-reported higher for Astaire. Using data from semi-structured interviews, we foreground design elements that impacted our participants' play experience, grouped under the themes of balance of players' roles, the physicality afforded by the game, and the social experience enabled. Our work contributes to opening the design space of hybrid collocated VR--through our game, we surface inspirational design concepts in HCI, and share design knowledge gained during our design process.},
	booktitle = {Proceedings of the Annual Symposium on Computer-Human Interaction in Play},
	pages = {5–18},
	numpages = {14},
	keywords = {alternative controllers, asymmetrical play, collocated play, embodied sketching, gestural excess, hybrid vr, mr, physicality, social play, social touch, spectatorship, vr},
	location = {<conf-loc>, <city>Barcelona</city>, <country>Spain</country>, </conf-loc>},
	series = {CHI PLAY '19}
}

@inproceedings{10.1145/571985.572016,
	author = {Booth, Kellogg S. and Fisher, Brian D. and Lin, Chi Jui Raymond and Argue, Ritchie},
	title = {The "mighty mouse" multi-screen collaboration tool},
	year = {2002},
	isbn = {1581134886},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/571985.572016},
	doi = {10.1145/571985.572016},
	abstract = {Many computer operating systems provide seamless support for multiple display screens, but there are few cross-platform tools for collaborative use of multiple computers in a shared display environment. Mighty Mouse is a novel groupware tool built on the public domain VNC protocol. It is tailored specifically for face-to-face collaboration where multiple heterogeneous computers (usually laptops) are viewed simultaneously (usually via projectors) by people working together on a variety of applications under various operating systems. Mighty Mouse uses only the remote input capability of VNC, but enhances this with various features to support flexible movement between the various platforms, "floor control" to facilitate smooth collaboration, and customization features to accommodate different user, platform, and application preferences in a relatively seamless manner. The design rationale arises from specific observations about how people collaborate in meetings, which allows certain simplifying assumptions to be made in the implementation.},
	booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
	pages = {209–212},
	numpages = {4},
	keywords = {collaboration, cut-and-paste, keyboard mappings, low-fidelity prototyping, single display groupware, virtual network computing},
	location = {Paris, France},
	series = {UIST '02}
}


@inproceedings{10.1145/3332165.3347938,
	author = {Wu, Te-Yen and Gong, Jun and Seyed, Teddy and Yang, Xing-Dong},
	title = {Proxino: Enabling Prototyping of Virtual Circuits with Physical Proxies},
	year = {2019},
	isbn = {9781450368162},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3332165.3347938},
	doi = {10.1145/3332165.3347938},
	abstract = {We propose blending the virtual and physical worlds for prototyping circuits using physical proxies. With physical proxies, real-world components (e.g. a motor, or light sensor) can be used with a virtual counterpart for a circuit designed in software. We demonstrate this concept in Proxino, and elucidate the new scenarios it enables for makers, such as remote collaboration with physically distributed electronics components. We compared our hybrid system and its output with designs of real circuits to determine the difference through a system evaluation and observed minimal differences. We then present the results of an informal study with 9 users, where we gathered feedback on the effectiveness of our system in different working conditions (with a desktop, using a mobile, and with a remote collaborator). We conclude by sharing our lessons learned from our system and discuss directions for future research that blend physical and virtual prototyping for electronic circuits.},
	booktitle = {Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology},
	pages = {121–132},
	numpages = {12},
	keywords = {breadboard, circuit construction, remote collaboration},
	location = {New Orleans, LA, USA},
	series = {UIST '19}
}


@inproceedings{10.1145/3332165.3347948,
	author = {Makiguchi, Motohiro and Sakamoto, Daisuke and Takada, Hideaki and Honda, Kengo and Ono, Tetsuo},
	title = {Interactive 360-Degree Glasses-Free Tabletop 3D Display},
	year = {2019},
	isbn = {9781450368162},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3332165.3347948},
	doi = {10.1145/3332165.3347948},
	abstract = {We present an interactive 360-degree tabletop display system for collaborative work around a round table. Users are able to see 3D objects on the tabletop display anywhere around the table without 3D glasses. The system uses a visual perceptual mechanism for smooth motion parallax in the horizontal direction with fewer projectors than previous works. A 360-degree camera mounted above the table and image recognition software detects users' positions around the table and the heights of their faces (eyes) as they move around the table in real-time. Those mechanics help display correct vertical and horizontal direction motion parallax for different users simultaneously. Our system also has a user interaction function with a tablet device that manipulates 3D objects displayed on the table. These functions support collaborative work and communication between users. We implemented a prototype system and demonstrated the collaborative features of the 360-degree tabletop display system.},
	booktitle = {Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology},
	pages = {625–637},
	numpages = {13},
	keywords = {autostereoscopic 3d, linear blending, smooth motion parallax, tabletop display},
	location = {New Orleans, LA, USA},
	series = {UIST '19}
}

@inproceedings{10.1145/2047196.2047207,
	author = {Hincapi\'{e}-Ramos, Juan David and Voida, Stephen and Mark, Gloria},
	title = {A design space analysis of availability-sharing systems},
	year = {2011},
	isbn = {9781450307161},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2047196.2047207},
	doi = {10.1145/2047196.2047207},
	abstract = {Workplace collaboration often requires interruptions, which can happen at inopportune times. Designing a successful availability-sharing system requires finding the right balance to optimize the benefits and reduce costs for both the interrupter and interruptee. In this paper, we examine the design space of availability-sharing systems and identify six relevant design dimensions: abstraction, presentation, information delivery, symmetry, obtrusiveness and temporal gradient. We describe these dimensions in terms of the tensions between interrupters and interruptees revealed in previous studies of workplace collaboration and deployments of awareness systems. As a demonstration of the utility of our design space, we introduce InterruptMe, a novel availability-sharing system that represents a previously unexplored point in the design space and that balances the tensions between interrupters and interruptees. InterruptMe differs from previous systems in that it displays availability information only when needed by monitoring implicit inputs from the system's users, implements a traceable asymmetry structure, and introduces the notion of per-communications channel availability.},
	booktitle = {Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology},
	pages = {85–96},
	numpages = {12},
	keywords = {availability, interruptibility, workplace awareness},
	location = {Santa Barbara, California, USA},
	series = {UIST '11}
}


@inproceedings{10.1145/3266037.3266086,
	author = {Cha, Yoonjeong and Nam, Sungu and Yi, Mun Yong and Jeong, Jaeseung and Woo, Woontack},
	title = {Augmented Collaboration in Shared Space Design with Shared Attention and Manipulation},
	year = {2018},
	isbn = {9781450359498},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3266037.3266086},
	doi = {10.1145/3266037.3266086},
	abstract = {Augmented collaboration in a shared house design scenario has been studied widely with various approaches. However, those studies did not consider human perception. Our goal is to lower the user's perceptual load for augmented collaboration in shared space design scenarios. Applying attention theories, we implemented shared head gaze, shared selected object, and collaborative manipulation features in our system in two different versions with HoloLens. To investigate whether user perceptions of the two different versions differ, we conducted an experiment with 18 participants (9 pairs) and conducted a survey and semi-structured interviews. The results did not show significant differences between the two versions, but produced interesting insights. Based on the findings, we provide design guidelines for collaborative AR systems.},
	booktitle = {Adjunct Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology},
	pages = {13–15},
	numpages = {3},
	keywords = {collaborative ar, human perception, shared space design},
	location = {Berlin, Germany},
	series = {UIST '18 Adjunct}
}


@inproceedings{10.5555/850976.854976,
	author = {Fiorentino, Michele and de Amicis, Raffaele and Monno, Giuseppe and Stork, Andre},
	title = {Spacedesign: A Mixed Reality Workspace for Aesthetic Industrial Design},
	year = {2002},
	isbn = {0769517811},
	publisher = {IEEE Computer Society},
	address = {USA},
	abstract = {Spacedesign is an innovative Mixed Reality (MR) application addressed to aesthetic design of free form curves and surfaces. It is a unique and comprehensive approach which uses task-specific configurations to support the design workflow from concept to mock-up evaluation and review. The first-phase conceptual design benefits from a workbench-like 3-D display for free hand sketching, surfacing and engineering visualization. Semi-transparentstereo glasses augment the pre-production physical prototype by additional shapes, textures and annotations. Both workspaces share a common interface and allow collaboration and cooperation between different experts, who can configure the system for the specific task. A faster design workflow and CAD data consistency can be thus naturally achieved. Tests andcollaborations with designers, mainly from automotive industry, are providing systematic feedback for this on-going research. As far as the authors are concerned, there is no known similar approach that integrates the creation and editing phase of 3D curves and surfaces in Virtual and Augmented Reality (VR/AR). Herein we see the major contribution of our new application.},
	booktitle = {Proceedings of the 1st International Symposium on Mixed and Augmented Reality},
	pages = {86},
	series = {ISMAR '02}
}


@inproceedings{10.1145/2380116.2380151,
	author = {Karnik, Abhijit and Martinez Plasencia, Diego and Mayol-Cuevas, Walterio and Subramanian, Sriram},
	title = {PiVOT: personalized view-overlays for tabletops},
	year = {2012},
	isbn = {9781450315807},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2380116.2380151},
	doi = {10.1145/2380116.2380151},
	abstract = {We present PiVOT, a tabletop system aimed at supporting mixed-focus collaborative tasks. Through two view-zones, PiVOT provides personalized views to individual users while presenting an unaffected and unobstructed shared view to all users. The system supports multiple personalized views which can be present at the same spatial location and yet be only visible to the users it belongs to. The system also allows the creation of personal views that can be either 2D or (auto-stereoscopic) 3D images. We first discuss the motivation and the different implementation principles required for realizing such a system, before exploring different designs able to address the seemingly opposing challenges of shared and personalized views. We then implement and evaluate a sample prototype to validate our design ideas and present a set of sample applications to demonstrate the utility of the system.},
	booktitle = {Proceedings of the 25th Annual ACM Symposium on User Interface Software and Technology},
	pages = {271–280},
	numpages = {10},
	keywords = {tabletop, multi-view, multi-user, lumisty},
	location = {Cambridge, Massachusetts, USA},
	series = {UIST '12}
}


@inproceedings{10.1145/3131785.3131841,
	author = {Lee, Sang Won},
	title = {Hybrid Use of Asynchronous and Synchronous Interaction for Collaborative Creation},
	year = {2017},
	isbn = {9781450354196},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3131785.3131841},
	doi = {10.1145/3131785.3131841},
	abstract = {My dissertation is aimed at enabling people to collaborate to create complex artifacts: for example, to develop software, sketch GUI prototypes, play music together, or write a novel. Such creative processes are not well defined and can evolve dynamically. We introduce interactive systems that help users collaborate and communicate in the open-ended process. In particular, we investigate the benefits of both integrating asynchronous interactions into real-time collaborations and of having real time components in asynchronous collaborative settings. The systems provide tools that combine the two different types of interaction techniques, and we validate them via user study, participatory performing arts, and the online deployments of systems and crowdsourced tasks. The hybrid methods are designed to help users recover collaborative context, make the process approachable to nonexperts, collaborate online crowds on demand in real-time, and sustain liveness during collaboration. The dissertation will result in cross-domain knowledge in designing collaborative systems and it will help us create a framework for future intelligent systems that will help people solve more complex tasks effectively.},
	booktitle = {Adjunct Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology},
	pages = {95–98},
	numpages = {4},
	keywords = {groupware, crowdsourcing, creativity, collaboration},
	location = {Qu\'{e}bec City, QC, Canada},
	series = {UIST '17 Adjunct}
}

@inproceedings{10.1145/3266037.3266102,
	author = {Feick, Martin and Tang, Anthony and Bateman, Scott},
	title = {Mixed-Reality for Object-Focused Remote Collaboration},
	year = {2018},
	isbn = {9781450359498},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3266037.3266102},
	doi = {10.1145/3266037.3266102},
	abstract = {In this paper we outline the design of a mixed-reality system to support object-focused remote collaboration. Here, being able to adjust collaborators' perspectives on the object as well as understand one another's perspective is essential to support effective collaboration over distance. We propose a low-cost mixed-reality system that allows users to: (1) quickly align and understand each other's perspective; (2) explore objects independently from one another, and (3) render gestures in the remote's workspace. In this work, we focus on the expert's role and we introduce an interaction technique allowing users to quickly manipulation 3D virtual objects in space.},
	booktitle = {Adjunct Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology},
	pages = {63–65},
	numpages = {3},
	keywords = {vr, object-focused remote collaboration, mixed reality, ar},
	location = {Berlin, Germany},
	series = {UIST '18 Adjunct}
}

@inproceedings{10.1145/3526113.3545637,
	author = {Peng, Yi-Hao and Wu, Jason and Bigham, Jeffrey and Pavel, Amy},
	title = {Diffscriber: Describing Visual Design Changes to Support Mixed-Ability Collaborative Presentation Authoring},
	year = {2022},
	isbn = {9781450393201},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3526113.3545637},
	doi = {10.1145/3526113.3545637},
	abstract = {Visual slide-based presentations are ubiquitous, yet slide authoring tools are largely inaccessible to people who are blind or visually impaired (BVI). When authoring presentations, the 9 BVI presenters in our formative study usually work with sighted collaborators to produce visual slides based on the text content they produce. While BVI presenters valued collaborators’ visual design skill, the collaborators often felt they could not fully review and provide feedback on the visual changes that were made. We present Diffscriber, a system that identifies and describes changes to a slide’s content, layout, and style for presentation authoring. Using our system, BVI presentation authors can efficiently review changes to their presentation by navigating either a summary of high-level changes or individual slide elements. To learn more about changes of interest, presenters can use a generated change hierarchy to navigate to lower-level change details and element styles. BVI presenters using Diffscriber were able to identify slide design changes and provide feedback more easily as compared to using only the slides alone. More broadly, Diffscriber illustrates how advances in detecting and describing visual differences can improve mixed-ability collaboration.},
	booktitle = {Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
	articleno = {35},
	numpages = {13},
	keywords = {Visual design, Slides, Presentation, Multimedia creation, Change descriptions and captioning, Authoring tools, Accessibility},
	location = {Bend, OR, USA},
	series = {UIST '22}
}

@inproceedings{10.1145/3383668.3419953,
	author = {Daronnat, Sylvain},
	title = {Human-Agent Trust Relationships in a Real-Time Collaborative Game},
	year = {2020},
	isbn = {9781450375870},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3383668.3419953},
	doi = {10.1145/3383668.3419953},
	abstract = {Collaborative virtual agents are often deployed to help users make decisions in real-time. For this collaboration to work, users must adequately trust the agents that they are interacting with. In my research, I use a game where human-agent interactions are recorded via a logging system and survey instruments in order to explore this trust relationship. I then study the impact that different agents have on reliance, performance, cognitive load and trust. I seek to understand which aspects of an agent influence the development of trust the most. With this research, I hope to pave the way for trust-aware agents, capable of adapting their behaviours to users in real-time.},
	booktitle = {Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play},
	pages = {18–20},
	numpages = {3},
	keywords = {trust, task difficulty, reliance, performance, hci, collaborative game, cognitive load, agents},
	location = {Virtual Event, Canada},
	series = {CHI PLAY '20}
}


@inproceedings{10.1109/ISMAR.2009.5336522,
	author = {Nilsson, Susanna and Johansson, Bjorn and Jonsson, Arne},
	title = {Using AR to support cross-organisational collaboration in dynamic tasks},
	year = {2009},
	isbn = {9781424453900},
	publisher = {IEEE Computer Society},
	address = {USA},
	url = {https://doi.org/10.1109/ISMAR.2009.5336522},
	doi = {10.1109/ISMAR.2009.5336522},
	abstract = {This paper presents a study where Augmented Reality (AR) technology has been used as a tool for supporting collaboration between the rescue services, the police and military personnel in a crisis management scenario. There are few studies on how AR systems should be designed to improve cooperation between actors from different organizations while at the same time support individual needs. In the present study an AR system was utilized for supporting joint planning tasks by providing organisation-specific views of a shared working. The study involved a simulated emergency event conducted in close to real settings with representatives from the organisations for which the system is developed. As a baseline, a series of trials without the AR system was carried out. Results show that the users were positive towards the AR system, and would like to use it in real work. They also experience some performance benefits of using the AR system compared to their traditional tools. Finally, the problem of designing for collaborative work as well as the benefits of using an iterative design processes is discussed.},
	booktitle = {Proceedings of the 2009 8th IEEE International Symposium on Mixed and Augmented Reality},
	pages = {3–12},
	numpages = {10},
	series = {ISMAR '09}
}


@inproceedings{10.1109/ISMAR.2009.5336478,
	author = {Ai, Zhuming and Livingston, Mark A.},
	title = {Integration of georegistered information on a virtual globe},
	year = {2009},
	isbn = {9781424453900},
	publisher = {IEEE Computer Society},
	address = {USA},
	url = {https://doi.org/10.1109/ISMAR.2009.5336478},
	doi = {10.1109/ISMAR.2009.5336478},
	abstract = {In collaborative augmented reality (AR) missions, much georegistered information is collected and sent to a command and control center. This paper describes the concept and prototypical implementation of a mixed reality (MR) based system that integrates georegistered information from AR systems and other sources on a virtual globe. The application can be used for a command and control center to monitor the field operation where multiple AR users are engaging in a collaborative mission. Google Earth is used to demonstrate the system, which integrates georegistered icons, live video streams from field operators or surveillance cameras, 3D models, and satellite or aerial photos into one MR environment.},
	booktitle = {Proceedings of the 2009 8th IEEE International Symposium on Mixed and Augmented Reality},
	pages = {169–170},
	numpages = {2},
	series = {ISMAR '09}
}

@inproceedings{10.5555/946248.946803,
	author = {MacWilliams, Asa and Sandor, Christian and Wagner, Martin and Bauer, Martin and Klinker, Gudrun and Bruegge, Bernd},
	title = {Herding Sheep: Live System Development for Distributed Augmented Reality},
	year = {2003},
	isbn = {0769520065},
	publisher = {IEEE Computer Society},
	address = {USA},
	abstract = {In the past, architectures of Augmented Reality systemshave been widely different and taylored to specific tasks. Inthis paper, we use the example of the SHEEP game to showhow the structural flexibility of DWARF, our component-basedDistributed Wearable Augmented Reality Framework,facilitates a rapid prototyping and online developmentprocess for building, debugging and altering a complex,distributed, highly interactive AR system.The SHEEP system was designed to test and demonstratethe potential of tangible user interfaces which dynamicallyvisualize, manipulate and control complex operations ofmany inter-dependent processes. SHEEP allows the usersmore freedom of action and forms of interaction and collaboration,following the tool metaphor that bundles softwarewith hardware in units that are easily understandable to theuser. We describe how we developed SHEEP, showing thecombined evolution of framework and application, as wellas the progress from rapid prototype to final demonstrationsystem. The dynamic aspects of DWARF facilitated testingand allowed us to rapidly evaluate new technologies.SHEEP has been shown successfully at various occasions.We describe our experiences with these demos.},
	booktitle = {Proceedings of the 2nd IEEE/ACM International Symposium on Mixed and Augmented Reality},
	pages = {123},
	series = {ISMAR '03}
}